# Design of an Efficient TTFS-SNN-Based EEG Emotion Recognition System on Lightweight FPGA
基于 TTFS-SNN 的高效 EEG 情绪识别系统轻量 FPGA 实现
## 摘要
**关键词：** Spiking Neural Network (SNN)；Depthwise Separable Convolution；Energy-Efficient；Lightweight

## 1. INTRODUCTION

情绪调节对人类的认知、决策与社会行为的影响至关重要，是理解心理状态与构建智能系统的关键。随着情感计算和人机交互的发展，情绪识别（Emotion Recognition）被视为连接生理信号与情绪体验的重要桥梁[1]。现实应用中，情绪具有持续、缓变和个体依赖的特征，要求监测系统能够在长期、低侵入性和能效受限的条件下稳定运行[2]。

EEG（脑电图）作为一种反映大脑神经活动的生理信号，具有毫秒级的时间分辨率和高时效性，成为情绪监测的理想选择。与心率、皮肤电或呼吸等外周信号不同，EEG能够记录情绪加工的中枢神经过程，不依赖外部行为表现[3-4]。EEG信号天然展现出高度的动态性与事件驱动特性，这使其能敏锐捕捉情绪因内外刺激而产生的即时反应与连续演变。同时，大脑功能活动在神经表征上的稀疏性特质，也为从复杂信号中高效解码特定情绪状态提供了理论基础[5]。

其毫秒级时间分辨率使系统能够捕捉情绪状态的瞬时波动，从而支持连续、细粒度的动态监测。同时，EEG传感器的可穿戴化与柔性化发展[6,7]显著降低了使用门槛，使低侵入、长时程采集成为可能。这些特性使EEG成为构建能效最优、可长期运行的情绪监测系统的理想信号来源。

在实际应用中，情绪识别系统的部署不仅需要处理EEG信号的复杂性，还必须考虑到边缘设备上计算能力和能效的限制。在资源受限的边缘设备上，实时推理、低功耗以及高效计算成为实现情绪识别系统的核心挑战。传统的计算平台如CPU/GPU，尽管在高计算需求下表现优秀，但其能耗高、计算密集，难以在能效受限场景保持高效运算[23, 24]； MCU 虽然具备较低的功耗，但其资源配置是固定的，计算能力和存储资源在设计时就已经确定。即使在某些计算任务中不使用所有的硬件模块，未启用的模块仍然存在并消耗功耗，这导致了额外的静态功耗。此外，MCU的并行算力有限，难以满足深度模型的复杂计算和低延迟需求[15, 16]。相对而言，现场可编程门阵列（FPGA）凭借其可重构并行架构和细粒度的数据流控制，提供了在边缘设备上加速计算的理想平台[25,26]。FPGA的硬件资源是可重构的，可以根据任务的需求动态配置，关闭不必要的模块，从而显著降低能耗。通过并行化与流水线化设计，energy-per-inference显著更优，并在延迟方面具有天然优势。同时，其设计理念与可移植性使其成为面向未来类脑 ASIC 架构的理想过渡平台。传统的 FPGA 多采用同步电路设计，其所有运算单元依赖统一的全局时钟信号进行触发与同步，但全局时钟的持续分配与切换会带来显著的动态功耗开销，同时在处理稀疏或事件驱动型信号时，仍需执行大量冗余运算，导致能效利用率较低。近年来，部分研究在 FPGA 上探索了异步电路的实现，通过事件驱动机制取代全局时钟信号，以实现按需触发的计算过程。该设计不仅显著降低了时钟网络的功耗，更契合生物神经系统的事件触发特性。此外，这种异步、事件驱动的计算方式使 FPGA 能够更高效地应对 EEG 信号中稀疏且动态变化的计算任务。

尽管 FPGA 为低功耗并行计算提供了理想的硬件载体，但要真正发挥其异步与事件驱动架构的优势，前提是运行其上的计算模型本身需具备事件触发或稀疏计算特性。当前主流的深度学习模型，如 V. J. Lawhern 等提出的 EEGNet [7]，在脑电特征提取中表现优异，但其结构仍依赖密集的乘加运算与层间同步机制，包括卷积、批归一化与时间步展开等操作，导致计算与存储开销较高，难以与异步硬件的按需计算模式相匹配。同样地，基于循环单元的时间序列模型，如用于情感识别的 LSTM [10]，依赖严格的时序更新与全局同步处理，难以在无全局时钟的事件驱动平台上实现高效并行化。此外，基于图卷积的 MSFR-GCN [12] 虽然在空间拓扑关系建模方面具有优势，但其对邻接矩阵运算与不规则内存访问的依赖进一步增加了 FPGA 上的实现复杂度与延迟开销。因此，尽管模型压缩、剪枝与量化等轻量化策略在一定程度上可降低运算负担，但在兼顾实时性与能效的条件下，传统的同步深度学习范式仍难以充分释放 FPGA 异步、事件驱动体系的潜力。

因此，解决这一问题的关键不仅在于算法优化，而在于计算范式的根本转变。作为类脑计算的核心，脉冲神经网络（SNN）凭借其事件驱动机制和稀疏激活特性，能够显著减少计算资源的消耗，同时与EEG信号的动态特性高度契合。通过仅在信号发生变化时激活神经元，SNN为实现低功耗、高效的实时推理提供了潜力，使其成为边缘设备上情绪识别系统的理想选择【10】。已有研究验证了 SNN 在情绪识别与压力检测任务中的可行性。例如，Kumar 等[20]在类脑硬件上实现了 EEG 信号解码，展示了低功耗情绪识别的潜力；Doborjeh 等[21]则利用递归式 SNN 有效建模了情绪动态过程。这些成果表明，类脑计算有望成为实现连续、实时、低功耗情绪识别的关键技术路径。

令人鼓舞的是，研究人员已经开始致力于解决这一挑战，提出了多种解决方案以突破性能瓶颈。具体而言，近年来提出的基于SNN的轻量化模型展示了其在资源受限设备上的应用潜力【25】【26】。具体的研究（FPGA+SNN并没有用在情绪识别上）然而，值得注意的是，尽管这些轻量化SNN模型在各个领域取得了显著进展，但将其与FPGA的可重构特性相结合，推动情绪识别系统在边缘设备上的应用，仍处于起步阶段。因此，如何在边缘设备上融合FPGA的可重构特性与SNN的事件驱动计算机制，从而实现实时、高效的EEG情绪识别，是目前亟待解决的问题。因此，本研究提出了一种创新的方案，结合 FPGA 的可重构特性与 SNN 的事件驱动计算机制，构建兼具低功耗、高并行与可扩展性的 EEG 情绪识别系统架构[18, 27]，具体的贡献如下：

1.面向EEG情绪识别提出了一种基于FPGA的轻量化系统，energy-per-inference低至并且保持了高精度和高实时性的优点。

2.在从软件层面设计了硬件友好的S-STE模块和基于TTFS的脉冲神经网络，提出了一种基于活动依赖的时间窗自适应调节机制，确保脉冲神经网络的训练稳定性。

3.在硬件层面构建了GALS（Globally Asynchronous, Locally Synchronous）架构，通过事件驱动的稀疏触发与模块级并行调度显著降低了时钟功耗并提升系统吞吐率。

[1] K. J. Wang, R. Vinjamuri, M. Alimardani, *et al.*, “NeuroDesign in Human-Robot Interaction: The making of engaging HRI technology your brain can't resist,” *Frontiers in Robotics and AI*, vol. 12, Art. no. 1699371, 2025.

[2] R. Pillalamarri and U. Shanmugam, “A review on EEG-based multimodal learning for emotion recognition,” *Artif. Intell. Rev.*, vol. 58, no. 5, p. 131, 2025.

[3] X. Li, D. Song, P. Zhang, et al., “Exploring EEG features in cross-subject emotion recognition,” *Front. Neurosci.*, vol. 12, p. 162, 2018.

[4] A. Y. Begum, E. E. Lawrence, M. Saravanan, et al., “Advanced biosignal processing and emotion recognition through artificial intelligence,” in *Applied Mathematical Modeling for Biomedical Robotics and Wearable Devices*. Academic Press, 2026, pp. 59–78.

[5] X. Li, Y. Zhang, P. Tiwari, et al., “EEG based emotion recognition: A tutorial and review,” *ACM Comput. Surv.*, vol. 55, no. 4, pp. 1–57, 2022.

[6] F. Wang, Y. Xue, X. Chen, and J. Li, “3D printed implantable hydrogel bioelectronics for electrophysiological monitoring and electrical modulation,” *Advanced Functional Materials*, vol. 34, no. 21, p. 2314471, 2024.

[7] K. Zheng, C. Zheng, L. Zhu, and Y. Liu, “Machine learning enabled reusable adhesion, entangled network-based hydrogel for long-term, high-fidelity EEG recording and attention assessment,” *Nano-Micro Letters*, vol. 17, no. 1, p. 281, 2025.









[5] F. Tian, et al., “The three-lead EEG sensor: Introducing an EEG-assisted depression diagnosis system based on ant lion optimization,” *IEEE Trans. Biomed. Circuits Syst.*, vol. 17, no. 6, pp. 1305–1318, 2023.

[6] J. Cheng, M. Chen, C. Li, et al., “Emotion recognition from multi-channel EEG via deep forest,” *IEEE J. Biomed. Health Inform.*, vol. 25, no. 2, pp. 453–464, 2020.

[7] V. J. Lawhern, A. J. Solon, N. R. Waytowich, et al., “EEGNet: a compact convolutional neural network for EEG-based brain–computer interfaces,” *J. Neural Eng.*, vol. 15, no. 5, p. 056013, 2018.

[8] R. T. Schirrmeister, J. T. Springenberg, L. D. J. Fiederer, et al., “Deep learning with convolutional neural networks for EEG decoding and visualization,” *Hum. Brain Mapp.*, vol. 38, no. 11, pp. 5391–5420, 2017.

[9] A. Seal, S. R. et al., “DeprNet: A deep convolution neural network framework for detecting depression using EEG,” *IEEE Trans. Instrum. Meas.*, vol. 70, pp. 1–13, 2021.

[10] S. Alhagry, A. A. Fahmy and R. A. El-Khoribi, “Emotion recognition based on EEG using LSTM recurrent neural network,” *Int. J. Adv. Comput. Sci. Appl.*, vol. 8, no. 10, 2017.

[11] K. Devarajan, S. Ponnan and S. Perumal, “Enhancing emotion recognition through multi-modal data fusion and graph neural networks,” *Intelligence-Based Medicine*, p. 100291, 2025.

[12] D. Pan, H. Zheng, F. Xu, et al., “MSFR-GCN: A multi-scale feature reconstruction graph convolutional network for EEG emotion and cognition recognition,” *IEEE Trans. Neural Syst. Rehabil. Eng.*, vol. 31, pp. 3245–3254, 2023.

[13] H. Barki, N. D. Mai and W. Y. Chung, “Optimized XGBoost for multimodal affective state classification using in-ear PPG and behind-the-ear EEG signals,” *IEEE J. Biomed. Health Inform.*, 2025.

[14] X. Yi, “Energy-efficient EEG-based epileptic seizure detection: A deep learning-based spiking neural network approach,” *Procedia Comput. Sci.*, vol. 266, pp. 908–915, 2025.

[15] J. Lin, W.-M. Chen, Y. Lin, et al., “MCUNet: Tiny deep learning on IoT devices,” in *Adv. Neural Inf. Process. Syst.*, vol. 33, 2020, pp. 11711–11722.

[16] R. Sanchez-Iborra and A. F. Skarmeta, “TinyML-enabled frugal smart objects: Challenges and opportunities,” *IEEE Circuits Syst. Mag.*, vol. 20, no. 3, pp. 4–18, 2020.

[17] W. Maass, “Networks of spiking neurons: the third generation of neural network models,” *Neural Netw.*, vol. 10, no. 9, pp. 1659–1671, 1997.

[18] X. Zhang, J. Zhang, H. Huang, et al., “An Asynchronous RISC-V-based SNN Processor with Custom ISA Extensions for Programmable On-Chip Learning,” in *Proc. 29th IEEE Int. Symp. Asynchronous Circuits Syst. (ASYNC)*, IEEE, 2025, pp. 1–8.

[19] J. Bartels, O. Gallou, H. Ito, et al., “An event-driven neural network for monitoring of epileptic seizures on low-power neuromorphic hardware,” *bioRxiv*, 2024.

[20] N. Kumar, G. Tang, R. Yoo, et al., “Decoding EEG with spiking neural networks on neuromorphic hardware,” *Trans. Mach. Learn. Res.*, 2022.

[21] W. Alzhrani, M. Doborjeh, Z. Doborjeh, et al., “Emotion recognition and understanding using EEG data in a brain-inspired spiking neural network architecture,” in *Proc. 2021 Int. Joint Conf. Neural Netw. (IJCNN)*, IEEE, 2021, pp. 1–9.

[22] Z. Aalam, S. Aziz, K. L. Lew, et al., “Real-Time Emotion Detection Using Artificial Intelligence: A Review,” *Int. J. Robot. Autom. Sci.*, vol. 7, no. 1, pp. 104–110, 2025.

[23] S. Mittal, “A survey of techniques for approximate computing,” *ACM Comput. Surv. (CSUR)*, vol. 48, no. 4, pp. 1–33, 2016.

[24] A. Reuther, P. Michaleas, M. Jones, et al., “Survey of machine learning accelerators,” in *Proc. 2020 IEEE High Performance Extreme Computing Conf. (HPEC)*, 2020, pp. 1–12.

[25] V. Sze, Y.-H. Chen, T.-J. Yang, et al., “Efficient processing of deep neural networks: A tutorial and survey,” *Proc. IEEE*, vol. 105, no. 12, pp. 2295–2329, 2017.

[26] K. Guo, S. Zeng, J. Yu, et al., “A survey of FPGA-based neural network inference accelerators,” *ACM Trans. Reconfig. Technol. Syst. (TRETS)*, vol. 12, no. 1, pp. 1–26, 2019.

[27] S. Liu, H. Chu, Y. Feng, et al., “PicoSleepNet: An ultra lightweight sleep stage classification by spike neural network using single-channel EEG signal,” *IEEE J. Biomed. Health Inform.*, 2025.

[28] A. G. Howard, M. Zhu, B. Chen, et al., “MobileNets: Efficient convolutional neural networks for mobile vision applications,” *arXiv preprint arXiv:1704.04861*, 2017.

[29] A. A. M. Andrew, “Spiking neuron models: Single neurons, populations, plasticity,” *Kybernetes*, vol. 32, no. 7/8, 2003.

[30] C. Eliasmith and C. H. Anderson, *Neural engineering: Computation, representation, and dynamics in neurobiological systems*. MIT Press, 2003.

[31] C. Kayser, M. A. Montemurro, N. K. Logothetis, et al., “Spike-phase coding boosts and stabilizes information carried by spatial and temporal spike patterns,” *Neuron*, vol. 61, no. 4, pp. 597–608, 2009.

[32] H. Mostafa, “Supervised learning based on temporal coding in spiking neural networks,” *IEEE Trans. Neural Netw. Learn. Syst.*, vol. 29, no. 7, pp. 3227–3235, 2017.

[33] M. Zhang, S. Wang, J. Wu, et al., “Toward energy-efficient spike-based deep reinforcement learning with temporal coding,” *IEEE Comput. Intell. Mag.*, vol. 20, no. 2, pp. 45–57, 2025.



## 2. METHODOLOGY AND ALGORITHM

当前，可穿戴 EEG 情绪识别设备的主要挑战在于传统深度神经网络的计算范式与 EEG 信号的生理特性存在根本不匹配。前者依赖密集且同步的矩阵运算，而后者本质上表现为稀疏、事件驱动的神经活动。这种差异导致现有模型难以在功耗和算力受限的设备上高效运行。为实现低功耗、低延迟的边缘情绪识别系统，需要一种既能充分捕获生物信号时空特征，又能在资源受限硬件上高效执行的新型计算架构。



### A.Neuron Model and TTFS Coding

脑电（EEG）信号作为一种典型的非平稳时序信号，蕴含了大量与情绪状态相关的动态信息，其时域波动与事件触发过程具有显著的时间依赖性。脉冲神经网络（Spiking Neural Network, SNN）通过膜电位积累、阈值触发与事件驱动的计算机制，能够以更生物启发的方式表达神经活动的时序特征，因而在EEG等时间敏感型任务中表现出潜在优势。

在SNN的设计中，神经元模型是定义时域动态与信息编码方式的关键。当前常用的脉冲神经元模型主要包括 Leaky Integrate-and-Fire (LIF) []、Izhikevich []、Hodgkin–Huxley (HH) [] 以及 Spike Response Model (SRM)[]。其中，HH模型能够精确刻画神经元膜电位的生理演化，被视为生物神经计算的黄金标准，但计算复杂度极高，难以部署在低功耗平台上。Izhikevich与SRM模型在生物真实性与计算效率之间取得平衡，但依然需要较高的资源开销。LIF 模型因其结构简洁、数学形式可离散化而成为工程实现中最常用的神经元模型。其膜电位随时间的演化可表示为

$V[t+1] = \alpha V[t] + I[t],$

其中，$\alpha = e^{-\Delta t / \tau} $为指数衰减因子，$I[t]$表示输入电流。这一形式在算法层面易于仿真，但在硬件实现中仍面临一定挑战：衰减项 $\alpha V[t]$ 需要在每个时间步执行一次乘法操作，而当网络规模较大时，大量乘法运算将占用可观的 DSP 资源或查找表，从而增加功耗并降低并行效率。尤其在 FPGA 或低功耗 SoC 等资源受限平台上，LIF 模型的指数衰减机制成为制约其实时部署与扩展能力的主要瓶颈。

为解决LIF等模型在计算和硬件实现上的局限性，并充分发挥SNN的稀疏计算优势，本研究在编码范式与神经元模型两个层面进行了协同设计。

<img src="%E8%AE%BA%E6%96%87.assets/image-20251028222808313.png" alt="image-20251028222808313" style="zoom:67%;" />

本研究采用的核心编码范式是首脉冲时间编码（Time-To-First-Spike, TTFS）。TTFS编码方式通过将更强的输入激转化为更早的脉冲发放时间，并且每个神经元在一个计算周期内最多只发放一个脉冲，实现了极致的脉冲稀疏性，确保了最低的理论功耗和最快的响应速度。此外，本文采用了B1脉冲神经元模型[]以契合该编码方式。B1模型的核心就是引入了一个级联时间窗（Cascading Time Window）机制，为TTFS编码提供了完美的硬件友好型实现框架。该模型的核心是将复杂的神经元动力学简化为一个分段线性的过程，省去了在硬件上实现成本高昂的指数运算与乘法衰减项。其动态特性由时间窗（Temporal Bounds）$[t_{\min}^{(n)}, t_{\max}^{(n)}]$ 划分为两个计算阶段。

网络的第 $n$ 层的时间窗 为$[t_{\min}^{(n)}, t_{\max}^{(n)}]$。每一层的$t_{\min}^{(n)}$被定义为上一层的$t_{\max}^{(n-1)}$，即 $t_{min}^{(n)} =^{def} t_{max}^{(n-1)}$。
其膜电位演化可描述为：
$$
\epsilon \frac{dV_i^{(n)}(t)}{dt} =
\begin{cases}
\sum_j W_{ij}^{(n)} H(t - t_j^{(n-1)}), & t < t_{\min}^{(n)} \quad  \\
1, & t_{\min}^{(n)} \le t \le t_{\max}^{(n)} \quad 
\end{cases}
$$
其中，$\epsilon$ 为时间常数，$H(\cdot)$ 为亥维赛阶跃函数，$W_{ij}^{(n)}$ 为突触权重。

在 $t < t_{\min}^{(n)}$ 的时间区间内，神经元膜电位 $\frac{dV_i^{(n)}}{dt}$ 的斜率由加权输入脉冲 $\sum_j W_{ij}^{(n)} H(t - t_j^{(n-1)})$ 决定。随后，在 $t_{\min}^{(n)} \le t \le t_{\max}^{(n)}$ 的时间区间内，膜电位斜率 $\frac{dV_i^{(n)}}{dt}$ 被固定为1，以恒定的速率开始线性增长。

对于第 $n$ 层的神经元 $i$，其输出脉冲的时刻 $t_i^{(n)}$ 是基于上一层的输入 $t_j^{(n-1)}$ 和阈值 $\vartheta_i^{(n)}$计算得出的。由B1模型的膜电位动力学，可直接推导出该前向传播方程如式（1）所示：

$$
t_i^{(n)} = t_{\min}^{(n)} + \tau_c \vartheta_i^{(n)} - \sum_j W_{ij}^{(n)} \bigl( t_{\min}^{(n)} - t_j^{(n-1)} \bigr) \quad
$$

若神经元i的脉冲发放时间 $t_i^{(n)}$ 超过本层的时间窗$t_{\max}^{(n)}$，该神经元便被视为未发放脉冲，在本计算周期内将保持沉默，不产生任何输出脉冲。

### B. Layer Structure

在资源受限的轻量级FPGA平台上设计神经网络时，模型的计算复杂度、功耗预算与推理延迟是与识别精度同等重要的核心考量[25, 26]。为实现算法性能与硬件效率的最佳平衡，本研究提出一种面向硬件优化的轻量级混合神经网络，将高效的时空特征提取与事件驱动的脉冲计算相结合，以弥合算法结构与信号特性之间的差距。==如图所示==，网络前端采用深度可分离卷积结构，用于高效提取 EEG 信号的时空特征并显著降低参数量和乘加复杂度。中间部分引入一种硬件友好的无除法 TTFS（time-to-first-spike）时间编码模块，将连续波形映射为稀疏脉冲序列，从而适配事件驱动计算机制。后端由基于TTFS编码的脉冲神经网络完成分类决策，在保持竞争性分类精度的同时，实现低功耗和低延迟推理。该架构在设计中充分考虑 FPGA 与可穿戴设备的实现约束，为实时、能效优化的 EEG 情绪识别提供了一种可行的技术途径。以下是上述三个模块的详细说明。

1）Efficient Spatio-temporal Feature Extraction Module

在处理多通道EEG信号时，首要挑战是如何在有限的硬件资源下高效捕获信号内部复杂的空间与时间依赖关系。传统的卷积神经网络（CNN）虽然表征能力强[]，但其标准的卷积操作涉及大量的乘加（MAC）运算和参数存储，这在资源受限的FPGA上会迅速消耗宝贵的DSP单元和BRAM资源，成为性能瓶颈。相关工作在轻量化网络架构方面已取得显著进展。如SqueezeNet 和 MobileNets [] 等研究已经证明，通过 $1 \times 1$ 卷积核压缩通道或将标准卷积分解为深度卷积和逐点卷积，可以在保持性能的同时极大降低模型复杂度。本模块即由深度可分离卷积作为网络的基础构建单元。其中深度卷积为输入的$C_{in}$个特征通道分别应用独立的卷积核，执行逐通道的空间滤波操作；之后，通过 $1 \times 1$ 卷积核对深度卷积的$C_{in}$个通道的输出进行线性组合，并将其映射到 $C_{out}$ 个输出通道。

| **运算类型**   | **参数量 (Parameters)**                                      | **计算成本 (MACs)**                                          |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 传统卷积       | $K^2 \cdot C_{in} \cdot C_{out}$                             | $K^2 \cdot C_{in} \cdot C_{out} \cdot H_{out} \cdot W_{out}$ |
| 深度可分离卷积 | $K^2 \cdot C_{in} + C_{in} \cdot C_{out}$                    | $(K^2 \cdot C_{in} + C_{in} \cdot C_{out}) \cdot H_{out} \cdot W_{out}$ |
| 成本降低比率   | $\frac{K^2 C_{in} + C_{in} C_{out}}{K^2 C_{in} C_{out}} = \frac{1}{C_{out}} + \frac{1}{K^2}$ |                                                              |

更重要的是，深度可分离卷积将复杂的运算分解为两个规整、独立的标准模块的特性为FPGA部署时提供了可拓展和可复用的硬件实现结构，使其极易于构建深度流水线（Pipeline）架构，实现硬件资源的高度复用与高吞吐量的实时数据处理。

整个时空特征提取模块的过程描述如下。

$$\left\{ \begin{aligned} H_{Block}^{(i)}(X) &= f_{ReLU}^{(i)}\left(f_{BN}^{(i)}\left(f_{PW}^{(i)}\left(f_{DW}^{(i)}(X)\right)\right)\right) \\ F_{out} &= H_{Block}^{(2)}\left(H_{Block}^{(1)}(F_{in})\right) \end{aligned} \right.$$

其中$F_{in}$是整个前端模块的输入特征图，$X$ 代表块函数的输入，$H_{Block}^{(i)}$ 是第 $i$ 个深度可分离卷积块，$f_{DW}^{(i)}$ 是第 $i$ 个块的Depthwise Convolution运算，$f_{PW}^{(i)}$ 是第 $i$ 个块的逐点卷积运算，$f_{BN}^{(i)}$ 是第 $i$ 个块的Batch Normalization运算，$f_{ReLU}^{(i)}$ 是第 $i$ 个块的ReLU激活函数，$F_{out}$ 是整个前端模块（的最终输出特征。

2）TTFS Temporal Encoding Module

将前端ANN模块提取的连续激活值转换为后端SNN所需的稀疏、离散的脉冲序列，是连接这两种计算范式的关键步骤。SNN的低功耗潜力源于其事件驱动的计算范式，即只有在接收到脉冲时才进行计算。因此，一个高效的编码机制应当以最少的脉冲数量来承载最丰富的信息。相关工作虽然探索了多种编码方案，但如速率编码（Rate Coding）[]、人口编码（Population Coding）[]与相位编码（Phase Coding）[]等，均因高延迟、高资源消耗或高实现复杂度，无法同时满足本系统对轻量化和实时性的严苛约束。

本模块采用了首脉冲时间编码（Time-To-First-Spike, TTFS），该机制将信息强度完整压缩在单个脉冲的精确发放时刻上，实现了极致的脉冲稀疏性与最低的理论延迟[]。然而，如下式所示，标准的TTFS编码机制依赖于浮点除法运算，这在硬件上实现代价高昂。

$$x_{norm} = \frac{x - x_{min}}{x_{max} - x_{min}}$$

为解决此问题，本模块采用了一种专为硬件优化的无除法TTFS编码器。其核心是将高成本的算术除法替换为不消耗逻辑单元的逻辑位移操作。==如式 所示==该机制首先在训练中跟踪激活值的动态范围scale；然后，它不直接使用该范围 scale作为除数，而是计算出一个大于scale的最小的2的整数次幂作为新的归一化分母$S_p$。

$x_{norm} = \frac{x - x_{min}}{2^N}$

整个TTFS编码模块的转换过程可描述如下：

$$\left\{ \begin{aligned} S_p &= 2^{\lceil \log_2(V_{max} - V_{min}) \rceil} \\ V_{norm} &= f_{clip}\left(\frac{F_{out} - V_{min}}{S_p}, 0, 1\right) \\ T_{spike} &= T_{max} - V_{norm} \cdot (T_{max} - T_{min}) \end{aligned} \right. $$

其中 $F_{out}$ 是来自前端卷积模块的输入特征， $V_{min}$ 和 $V_{max}$ 是训练时跟踪的激活值动态范围， $S_p$ 是计算出的二次幂缩放因子，$f_{clip}$ 是钳位函数， $T_{spike}$ 是最终输出的脉冲时间。

3）Adaptive Temporal Spiking Neural Module

本模块是系统的事件驱动决策后端，负责处理由TTFS编码器 生成的稀疏时序脉冲（$T_{spike}$），并实现最终的情绪类别判别。该模块基于多层全连接的脉冲神经元构建，其设计充分发挥了SNN的低功耗潜力，并通过时序编码捕捉EEG信号的动态特征。

该网络架构的核心特点在于信息处理在时间维度上的级联划分（Cascading Time Window）。网络的每一层（$n$）都在一个专属的、连续的时间窗 $[T_{min}^{(n)}, T_{max}^{(n)}]$ 内进行运算。层与层之间的时间窗首尾相连，即 $T_{min}^{(n)} =^{def} T_{max}^{(n-1)}$，确保了信号能够有序地、逐层地在时间维度上传播。

为适配TTFS编码，该模块的前向传播逻辑区分了隐藏层与输出层。隐藏层的功能是对输入的脉冲时间向量 $T_j^{(n-1)}$ 进行非线性时域变换。根据式（1），对于第 $n$ 层的神经元 $i$，其输出脉冲时刻 $T_i^{(n)}$ 由下式得出。

$$T_i^{(n)} = f_{clip}\left( \sum_j W_{ij}^{(n)} (T_j^{(n-1)} - T_{min}^{(n)}) + \vartheta_i^{(n)} + T_{min}^{(n)}, \ T_{min}^{(n)}, T_{max}^{(n)} \right)$$

其中 $W_{ij}^{(n)}$ 是权重，$\vartheta_i^{(n)}$ 是可训练的阈值， $f_{clip}$ 函数确保脉冲时间在$[T_{min}^{(n)}, T_{max}^{(n)}]$内。

然而，在TTFS编码范式中，时间窗 $[T_{min}, T_{max}]$ 是一个核心超参数，它直接影响信息表示的分辨率和训练的稳定性。在深度网络训练过程中，各层激活值的统计分布是动态变化的，采用一个静态、预设的时间窗会严重制约模型的学习与表达能力。要理解其局限性，我们必须首先分析该模块的梯度传播特性。

根据隐藏层的正向传播计算，并应用链式法则，我们可以推导出总损失 $L$ 对特定权重 $W_{ij}^{(n)}$ 的梯度 $\frac{\partial L}{\partial W_{ij}^{(n)}}$为

$$\frac{\partial L}{\partial W_{ij}^{(n)}} = \frac{\partial L}{\partial T_i^{(n)}} \cdot \frac{\partial T_i^{(n)}}{\partial W_{ij}^{(n)}} = \frac{\partial L}{\partial T_i^{(n)}} \cdot (T_j^{(n-1)} - T_{min}^{(n)})$$

这个梯度公式清晰地揭示了，权重的更新幅度与梯度项 $(T_j^{(n-1)} - T_{min}^{(n)})$ 强相关。这直接导致了时间窗设置不当会有梯度不稳定的风险。因此，一个静态的时间窗无法适应网络训练中动态变化的激活值分布。为此，我们引入了基于活动依赖的在线时间窗调整机制。该机制在每个训练批次中实时监控各隐藏层的脉冲发放动态，并据此对后续层级的时间窗进行动态重校准。

该机制的具体实现是一种乘性增益控制：在每个训练迭代中，系统会首先实时记录当前层 $n$ 在所有样本中产生的最早脉冲时间 $T_{earliest}^{(n)}$。基于该时间，机制采用乘性增益规则来调整时间窗，其新的时间窗上界 $T_{max, new}^{(n)}$ 由以下更新规则计算得出：

$$T_{max, new}^{(n)} = T_{max}^{(n)} + \lambda \cdot \left( (T_{earliest}^{(n)} - T_{min}^{(n)}) - \frac{T_{max}^{(n)} - T_{min}^{(n)}}{2} \right)$$

其中，$\lambda$ 是控制调整速率的唯一超参数。该规则根据最早脉冲时间与窗口中心的偏离程度，对当前窗口大小进行乘性缩放，以实现双向自适应调整。调整后的时间窗边界 $T_{max, new}^{(n)}$ 随即被传递至下一层，作为其新的起始时间 $T_{min}^{(n+1)}$。

4）Output Layer

输出层被设计为非脉冲的积分单元，其职责是将在其时间窗口内接收到的所有脉冲影响进行积分。在窗口结束时，神经元 $i$ 内部累积的总电位值（Logit）$L_i$ 可得出：

$$L_i = \sum_j W_{ij}^{(L)} (T_{min}^{(L)} - T_j^{(L-1)}) + (T_{max}^{(L)} - T_{min}^{(L)} - \vartheta_i^{(L)})$$

此过程通过时域稀疏解码，将时间域信息转换回幅度域的决策值，选择Logit最大的神经元作为最终的分类。

| Layer                                    | Output Size                              |
| ---------------------------------------- | ---------------------------------------- |
| Input EEG                                | (N, C, H, W)                             |
| Depthwise Conv 1                         | (N, C, H, W)                             |
| Pointwise Conv 1                         | (N, 2*C, H, W)                           |
| BatchNorm + ReLU                         | (N, 2*C, H, W)                           |
| Depthwise Conv 2                         | (N, 2*C, H/2, W/2)                       |
| Pointwise Conv 2                         | (N, 4*C, H/2, W/2)                       |
| BatchNorm + ReLU                         | (N, 4*C, H/2, W/2)                       |
| DivisionFreeAnnToSnnEncoder              | (N, 4*C, H/2, W/2)                       |
| Flatten                                  | (N, (4*C) $\times$ (H/2) $\times$ (W/2)) |
| Adaptive Temporal Spiking Neural Module1 | (N, 64)                                  |
| Adaptive Temporal Spiking Neural Module2 | (N, 32)                                  |
| Output Layer                             | (N, Class)                               |

\*: N is Batch size; C is Input channels; H and W are sample length and width. Depthwise Conv uses a 3x3 kernel (padded). Pointwise Conv uses a 1x1 kernel. Conv 1 Stride is 1; Conv 2 Stride is 2. 

## 3. HARDWARE ARCHITECTURE

本文在算法层面所提出的混合网络架构，旨在融合 $\textit{CNN}$ 强大的时空特征表征能力与 $\textit{SNN}$ 事件驱动计算的能效优势。然而，这种算法层面的互补，在硬件实现上引入了一个根本性的挑战：前端 $\textit{CNN}$ 本质上是数据驱动的，它依赖于连续、高吞吐量的同步流水线计算；而后端 $\textit{SNN}$ 则是事件驱动的，其低功耗特性源于非必要不计算的异步、稀疏处理模式。这两种计算范式在时钟速率、功耗模型和数据流特性上存在着根本的不匹配。为解决这一核心矛盾，本研究在顶层设计上提出了一种全局异步、局部同步即 $\textit{GALS}$ 的硬件架构。

==如图X所示的顶层架构概念图==，该架构将整个系统在物理上解耦为两个独立的时钟域。一个域是为高吞吐量优化的流式计算引擎；另一个域则是为超低功耗优化的事件处理流水线。这两个局部同步的计算域，通过一个专用的异步握手接口进行连接，构成了全局异步的数据交换。这种设计上的解耦，使得两个子系统可以被独立优化，而异步接口则保证了它们之间的鲁棒通信。本章将从这两个局部同步域的内部设计，以及连接它们的全局异步接口三个方面展开详细论述。

### A. 高效流式CNN计算引擎

$\textit{GALS}$ 架构中的 $\textit{clk\_cnn}$ 域，即 $\textit{CNN}$ 特征引擎，其核心设计目标是构建一个全流式的深度流水线。这种架构摒弃了传统实现中高成本的帧缓冲方案，转而采用即算即用的策略，旨在以最小的片上存储资源占用，实现对连续 $\textit{EEG}$ 数据流的高吞吐量处理。

为实现这一目标，架构采用了以运用行缓冲思想的 $\textit{SW}$ 即 $\textit{Stream Weaver}$ 模块为核心来代替传统的帧缓冲。在轻量级 $\textit{FPGA}$ 实现中，片上 $\textit{BRAM}$ 资源尤为宝贵，该模块的精巧之处在于它仅需缓存计算卷积窗口所必需的几行数据，从而极大地降低了对 $\textit{SRAM}$ 的需求。==如图X所示的行缓冲工作示意图==，$\textit{SW}$ 模块内部主要由两个行缓冲队列 $\textit{Line Buffer Queue}$ 和一个 $3 \times 3$ 的窗口寄存器阵列构成。其工作机制遵循一个精巧的移位-加载-更新流水线：在每个时钟周期，当一个新的 $\textit{EEG}$ 特征值 $S_t$ 从数据流输入时，模块的 $3 \times 3$ 窗口寄存器阵列首先整体进行一次列向移位，为新数据腾出空间并丢弃最旧的一列特征值；随后，新的数据列被实时构建，当前输入值 $S_t$ 被直接加载到窗口的右下角，而新列的另外两个值则分别从两个行缓冲队列的对应位置读出，填入窗口的右上角和中右侧，从而瞬间形成一个完整的、更新后的 $3 \times 3$ 特征窗口。与此同时，为处理后续的数据行，两个行缓冲队列也进行级联式更新，当前输入值 $S_t$ 被写入第一个行缓冲队列，而第一个队列中被推出的数据则同步写入第二个行缓冲队列。通过这种级联式的数据流动，$\textit{SW}$ 模块将一维的时间序列信息高效地转换成了二维的空间结构。这种即收即用的流式窗口生成机制，是整个 $\textit{CNN}$ 引擎能够以极低内存占用实现高效处理的基石。

经由时空转换器生成的 $3 \times 3$ 窗口，被直接送入一个深度级联的处理单元 $\textit{PE}$ 流水线。该==流水线如图X所示==，其架构由三个专用的、深度流水线化的计算模块级联而成，严格遵循深度可分离卷积的数据流：

首先，数据进入深度卷积 $\textit{DWConv}$ 单元。该单元通过一个三级流水线结构完成窗口与卷积核的点积运算，从而在每个有效时钟周期内均能产出一个累加结果，实现了计算资源的最大化利用。

紧接着，其结果流入逐点卷积 $\textit{PWConv}$ 单元。该单元接收来自上一级所有通道的特征累加值，构成一个输入特征向量。为了在资源和性能之间取得平衡，该单元并未采用完全并行的硬件结构，而是通过一个有限状态机 $\textit{FSM}$ 在连续的多个时钟周期内依次调度输入向量中的元素与对应的权重进行乘累加操作，最终将所有输出通道的结果并行输出。这种时分复用的设计显著降低了乘法器的硬件开销。

流水线的末端是量化激活核心 $\textit{QAC}$，它承载了本架构中一个关键的算法-硬件协同优化。==如图X所示==，它将批量归一化 、$\textit{ReLU}$ 和量化等多个操作预先融合，固化为一个紧凑的四级整数流水线，依次执行偏置加法、尺度乘法、算术右移和零点加法，彻底消除了推理过程中的浮点运算。综上所述，$\textit{CNN}$ 引擎通过时空转换器和 $\textit{PE}$ 流水线的紧密耦合，在 $\textit{clk\_cnn}$ 域内构建了一个从输入到输出完全流式化、无片外缓存依赖的特征提取引擎，实现了设计所需的最小资源占用和最大数据吞吐量。

### B. GALS桥

$\textit{GALS}$ 架构的核心在于连接 $\textit{clk\_cnn}$ 和 $\textit{clk\_snn}$ 两个独立时钟域的全局异步接口。该接口的设计必须解决两个层面的挑战，一是数据表征的转换，二是物理时钟域的跨越。

首先，接口必须解决两种计算范式在数据表征上的根本不匹配。前端 $\textit{CNN}$ 引擎的输出是并行的、密集的特征向量，而 $\textit{SNN}$ 的输入则必须是串行的、稀疏的脉冲事件。为此，一个专用的数据格式转换模块被部署在 $\textit{clk\_cnn}$ 域的末端。该模块接收来自 $\textit{PE}$ 流水线的并行特征向量，根据 $\textit{TTFS}$ 编码机制计算出脉冲发放时间，并将其串行化。它通过一个内部有限状态机 $\textit{FSM}$ 逐一输出 $\textit{AER}$ 脉冲流，每个脉冲都伴随着一个请求 $\textit{valid}$ 信号。

这个请求信号，连同来自 $\textit{SNN}$ 域的确认信号，共同构成了跨越异步边界的物理桥梁。==如图X所示的异步握手示意图==，该桥接采用了经典的双触发器同步器分别对这两个单比特控制信号进行安全采样，从而有效避免了亚稳态的产生。

这种请求-确认握手协议的实现是 $\textit{GALS}$ 架构鲁棒性的关键。它构建了一个速率无关的弹性接口。作为数据生产者的 $\textit{CNN}$ 引擎在发出一个脉冲后必须暂停，直到接收到消费者 $\textit{SNN}$ 引擎反馈的确认信号后，才能发送下一个脉冲。该机制允许低功耗的 $\textit{clk\_snn}$ 域根据其自身处理延迟，对高吞吐量的 $\textit{clk\_cnn}$ 域施加反压，从而在解耦两个计算范式、允许其独立优化的同时，确保了数据在跨越异步边界时的完整性与系统稳定性。

### C.事件驱动的SNN稀疏流水线 

$\textit{SNN}$ 引擎作为 $\textit{GALS}$ 架构的消费者，运行在独立的 $\textit{clk\_snn}$ 时钟域中。其设计的核心原则是非必要不计算，以最大限度地发挥事件驱动计算的低功耗优势。

该引擎通过一个顶层的全局控制逻辑来实现事件驱动。在没有事件输入时，整个 $\textit{clk\_snn}$ 域的流水线处于时钟门控的空闲状态，动态功耗接近于零。只有当 $\textit{GALS}$ 异步接口传来第一个有效的脉冲请求时，该控制逻辑才会被激活，从而驱动 $\textit{SNN}$ 引擎，使其开始执行其局部的同步流水线计算。

$\textit{SNN}$ 引擎本身即是一个由 $\textit{SNN}$ 计算层与层间 $\textit{AER}$ 桥接器交错构成的深度流水线。首先，$\textit{AER}$ 脉冲事件被送入流式 $\textit{SNN}$ 计算层。该层包含一个输入 $\textit{FIFO}$ 以增强流水线的弹性与鲁棒性，其后的 $\textit{SNN}$ 核心模块通过一个有限状态机 $\textit{FSM}$，严格按照 $\textit{TTFS}$ 的神经元动力学执行累加-输出计算。

在 $\textit{SNN}$ 的多层结构中，维持事件的稀疏性至关重要。因此，在层与层之间，我们设计并实现了一个专用的地址事件表示 $\textit{AER}$ 接口单元。==如图X所示的 $\textit{AER}$ 桥微架构==，它主要由三部分协同工作：一个用于临时缓存并行数据的片上脉冲时间存储器、一个用于生成事件地址并顺序扫描该存储器的地址扫描计数器，以及一个作为核心控制中枢的有限状态机 $\textit{FSM}$。该单元的工作流程由其内部控制器精密调度。当接收到启动信号后，模块首先执行一次高速并行写操作，将上一计算层总线上承载的整个发放时间向量，在单个时钟周期内完整地捕获并锁存至内部的片上存储器。数据捕获完成后，控制器立即驱动地址扫描计数器从零开始，对存储器进行逐点、顺序地轮询访问。在此过程中，一个关键的硬件稀疏化步骤是，如果脉冲发放的时间 $T_i^{(n)}$ 超过 $T_{max}^{(n)}$，该脉冲将被硬件自动过滤，不产生任何输出事件。只有有效的 $\textit{AER}$ 事件被逐一发送到下一个 $\textit{SNN}$ 计算层。这种计算-桥接-计算的串行流水线结构，确保了事件驱动的稀疏特性在整个 $\textit{SNN}$ 后端中得以保持。

在流水线的末端，最后一个 $\textit{SNN}$ 层的串行脉冲流被一个串并转换模块收集，解码回并行的 $\textit{Logit}$ 向量输入 $\textit{ArgMax}$ 单元对该向量进行比较，计算出最终的分类结果。当最终决策完成后，该单元发出的完成信号将复位顶层的全局控制逻辑，使 $\textit{SNN}$ 引擎重新进入低功耗的空闲状态，等待下一次脉冲事件的到来。

## 4. IMPLEMENTATION AND RESULTS

A. Experimental Details

1）Datasets

为保证与既往研究的可比性，本研究仅采用公开的**EEG**数据集作为评估基准：SEED 系列（SEED、SEED-IV、SEED-V）、DEAP 与 DREAMER。SEED 由上海交通大学 BCMI 团队采集，包含 15 名受试者的 62 通道 EEG，三次会话记录，刺激为若干电影片段（单段约 4 分钟），常见预处理包括下采样至 200 Hz、带通滤波及频域特征（如差分熵）提取（Zheng et al., 2016）。SEED-IV 为 SEED 在情感类别上的四类扩展，保留 62 通道与多会话设计，常用于四分类任务验证；SEED-V 则在被试规模与情感细粒度上进一步扩展并提供预计算的频域特征，便于更细致的情感分类比较。DEAP 包括从 32 名受试者（17 名男性、15名女性）收集的 32 通道脑电图数据。受试者的情绪是通过一分钟长的音乐视频剪辑来诱导的。每次刺激后，受试者都会根据 Russell （1980） 提出的二维情绪量表对他们的情绪体验进行评分。DREAMER 采用便携设备采集约 23 名被试的 14 通道 EEG（采样 128 Hz），因其轻量 EEG 配置常被用于轻量化模型的性能验证。为保证比较公平性，本研究在所有数据集上仅使用 EEG 通道，统一采用各自通用的预处理约定，随后将处理结果用于后续特征提取与分类评估。

2） Data preprocessing

本研究的数据预处理流程旨在从原始的多通道脑电（EEG）信号中提取具有判别性的时空特征，并对其进行平滑处理以增强信号的稳定性。整个流程主要包括基线校正、数据分段、特征提取、空间映射和时间动态平滑，具体步骤如下。

首先，我们对原始的多通道脑电信号进行基线校正。采用Z-Score标准化方法，利用每个试次（trial）开始前一段时间的静息态数据作为基线。具体而言，我们计算基线时段内每个通道信号的平均值和标准差，并利用这两个统计量对整个试次的信号进行标准化处理。该步骤有效地移除了通道间的基线漂移，并减少了不同试次间的信号差异。

完成基线校正后，我们将连续的脑电信号分割成固定长度的样本。我们使用一个固定长度的非重叠滑动窗口对每个试次的数据进行分割。为了更好地捕捉信号的动态变化，每个样本被进一步分解为多个连续的、更短的时间帧，形成一个维度为 T × C × S 的张量，其中T代表时间帧的数量，C为通道数，S为每个时间帧的采样点数。

接下来是特征提取阶段。针对每个时间帧，我们计算其功率谱熵（Power Spectrum Entropy, PSE）作为核心特征。功率谱熵能够有效衡量信号在频域中的不确定性或复杂性。通过该计算，T × C × S 的原始信号样本被转换为一个 T × C 的特征矩阵。
$$
H_{\mathrm{PSE}} = -\sum_{i=1}^{S} p_i \ln(p_i), \quad 
p_i = \frac{P(f_i)}{\sum_{j=1}^{S} P(f_j)}
$$

其中：$P(f_i)$是信号在频率$f_i$处的功率谱密度；$p_i$是归一化后的功率分布；$N$是频率点数；$ln$是自然对数。

为了保留并利用电极在头皮上的空间拓扑信息，我们将提取的多通道特征映射到一个二维网格中。该映射关系根据标准电极系统的物理位置来确定，使得空间上相邻的电极在特征图上也保持邻近。经过此步骤，每个样本被表示为多个连续的二维特征图，构成了一个具有时空结构的特征序列。

最后，为了对特征序列进行平滑处理并建模其内在的时间动态性，我们引入了线性动力学系统（Linear Dynamical System, LDS）对每个试次内的特征序列进行时间上的平滑。

|          | Sample Shape |         |                |
| -------- | ------------ | ------- | -------------- |
| Datasets | SIZE         | CHANNLE | Sliding window |
| SEED     | 8*9          | 4       | 1s             |
| SEED IV  | 8*9          | 4       | 1s             |
| SEED V   | 8*9          | 4       | 1s             |
| DEAP     | 6*7          | 6       | 1.5s           |
| DREAMER  | 4*5          | 9       | 1.5s           |

 

### B. Experimental Settings:

整个实验环境基于如下计算机配置：12 核 vCPU Intel(R) Xeon(R) Platinum 8255C 处理器（主频 2.50 GHz）与 NVIDIA GeForce RTX 2080 Ti（11 GB 显存）GPU，运行在 Ubuntu 22.04 系统下的 Python 3.12 环境中，使用 PyTorch 2.3.0 与 CUDA 12.1。
对于机器学习模型，我们参考了以往研究的经验并尝试寻找最优参数；对于深度学习模型，采用 Adamw优化器 来最小化交叉熵损失函数，学习率设为1e-4，batch size为 8，epoch设为 300，并使用早停防止过拟合。

随后，我们采用多种指标对所提出的 LSNNet 模型进行客观评估，包括 准确率（Acc）、特异性（Spe）、敏感性（Sen）、精确率（Pre） 以及 F1-score（F1） 。实验结果以平均值（mean） 和 标准差（Std） 的形式给出。

$\begin{matrix}Acc\mathrm{=}\frac{TP\mathrm{+}TN}{TP\mathrm{+}TN\mathrm{+}FP\mathrm{+}FN}\end{matrix}$

$\begin{matrix}Spe\mathrm{=}\frac{TN}{TN\mathrm{+}FP}\end{matrix}$

$\begin{matrix}Sen\mathrm{=}\frac{TP}{TP\mathrm{+}FN}\end{matrix}$

$\begin{matrix}Pre\mathrm{=}\frac{TP}{TP\mathrm{+}FP}\end{matrix}$

$\begin{matrix}F\mathrm{1=}\frac{\mathrm{2×}Pre\mathrm{×}Sen}{Pre\mathrm{+}Sen}\end{matrix}$

其中，$(TP)\mathrm{、}(TN)\mathrm{、}(FP)\mathrm{、}(FN)$分别表示真正例（True Positive）、真反例（True Negative）、假正例（False Positive）和假反例（False Negative)。

此外，为了评估模型的计算效率，我们采用 浮点运算量（FLOPs） 和 乘加运算量（Mult-Adds） 来衡量模型的整体计算复杂度。最后，将训练好的模型进行INT8量化后部署在 Xilinx Zynq-7000 SoC (XC7Z020-2CLG400) 平台上，以评估其硬件资源占用情况，其中 LUT、LUTRAM、FF 与BRAM 被用于测量模型在硬件上的最小存储资源需求。

### C. Classification Results

 

### D. ASIC Implementation

### 5.2 模型性能分析

软件：不同模型架构的性能对比：准确率、精确率、召回率、F1分数等指标
混淆矩阵：各类情绪分类的预测结果
鲁棒性分析：加入不同强度的高斯噪声，模拟实际工作环境

**后端消融对比**

- **目的：** 证明SNN后端 相较于传统ANN后端在能效上的巨大优势。
- **设计：** 保持前端（`DepthwiseSeparableConv`）完全一致。构建一个基线模型，将其后端的 `SpikingDense` 层 替换为等效拓扑的 `nn.Linear` 层。在相同条件下训练后，对比二者的**验证精度**（应相近）与**计算成本**（SNN的平均脉冲数 vs. ANN的MACs）。

**前端消融对比**

- **目的：** 证明深度可分离卷积（DSC）前端 相较于传统卷积在计算成本上的优越性。
- **设计：** 保持后端（`SpikingDense`）完全一致。构建一个对照组模型，将其前端的 `DepthwiseSeparableConv` 替换为 `nn.Conv2d`（标准卷积）。对比二者的**验证精度**（应相近）以及前端的**参数量**和**MACs**。

### 5.3 硬件性能分析
FPGA的实际准确率
吞吐量
FPGA资源占用
量化分析：从32、16位、8位、6位到4位

## 6. CONCLUSION
### 6.1 研究总结
### 6.2 未来工作展望
