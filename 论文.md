# Design of an Efficient TTFS-SNN-Based EEG Emotion Recognition System on Lightweight FPGA
基于 TTFS-SNN 的高效 EEG 情绪识别系统轻量 FPGA 实现
## 摘要
**关键词：** Spiking Neural Network (SNN)；Depthwise Separable Convolution；Energy-Efficient；Lightweight

## 1. INTRODUCTION

情绪在人类的认知、决策与社会交互过程中扮演着核心角色。随着人机交互、情感计算与心理健康监测等领域的快速发展，情绪识别（Emotion Recognition）已成为构建智能化系统的重要基础[1]。然而，当前的科学挑战不仅在于识别离散的情绪类别，更在于理解并持续追踪个体情绪状态的动态演化过程。现有研究多集中于短时、刺激驱动的情绪分类任务，而现实环境中的智能系统亟需具备长期、低侵入性、个体化的情绪监测能力，以适应个体差异与情境变化[2]。因此，这要求情绪识别方法从离散分类任务转向连续表征与个体化建模的新研究范式。

在情感计算中，面部表情、语音信号、语义文本及生理指标等多模态特征已被广泛用于情绪识别。然而，这些外显信号往往容易受到环境光照、语境差异及文化因素的影响，从而影响识别的稳定性与普适性[3]。相比之下，脑电图（EEG）能够直接反映大脑在情绪加工过程中的神经电活动，不依赖外部表现形式。凭借毫秒级时间分辨率，EEG 可以捕捉情绪状态的瞬时动态变化，为揭示情绪的神经机制及实现高精度识别提供了独特优势[4]。随着可穿戴技术与柔性电极材料的不断进步，轻量化 EEG 设备的出现使得连续、非侵入式情绪监测成为可能，为构建真正以人为中心的情绪计算系统奠定了基础。

在EEG情绪识别领域，传统机器学习（ML）方法，如支持向量机（SVM）、k近邻（kNN）及随机森林（RF）一直是研究的基础。近年来，许多工作致力于通过引入新的优化算法[5]或构建集成模型[6]来改进这些经典方法。然而，这些改进后的方法在根本上仍依赖于繁琐的信号预处理和人工特征提取，导致模型泛化性受限。为克服人工特征工程的局限并进一步提升模型性能，研究重心逐渐转向深度学习模型。以卷积神经网络（CNN）[7, 8, 9]、循环神经网络（RNN）[10]和图卷积网络（GNN）[11, 12]为代表的模型，凭借强大的时空特征自动学习能力，在多个公开数据集上取得了领先的分类精度。然而，这些模型的卓越性能与可穿戴设备的低功耗、低延迟需求之间存在内在矛盾。一方面，深度模型通常依赖大规模参数与密集乘加（MAC）运算，计算与存储代价高昂；另一方面，其同步、密集的计算范式与 EEG 信号的稀疏、动态特性存在根本不匹配[13, 14]。即便采用模型压缩、剪枝或量化等轻量化技术，仍难在边缘设备上兼顾能效与实时性[15, 16]。因此，解决该问题的关键不在于算法微调，而在于计算范式的根本转变。

受生物神经系统启发的类脑计算提供了一种全新的能效最优计算思路。脉冲神经网络作为类脑计算的核心模型，采用异步、事件驱动的计算机制，仅在触发事件时激活神经元，从而显著降低动态功耗并减少冗余计算[17, 19]。这种稀疏触发特性与 EEG 信号的稀疏、动态特性高度契合，使得 SNN 在建模情绪相关脑电动态时具有天然优势。已有研究验证了 SNN 在情绪识别与压力检测任务中的可行性。例如，Kumar 等[20]在类脑硬件上实现了 EEG 信号解码，展示了低功耗情绪识别的潜力；Doborjeh 等[21]则利用递归式 SNN 有效建模了情绪动态过程。这些成果表明，类脑计算有望成为实现连续、实时、低功耗情绪识别的关键技术路径。

在面向边缘的情感识别的设备中，实时低能耗推理是核心挑战[22]。通用 CPU/GPU 指令驱动且能耗高，难以在能效受限场景保持高效运算[23, 24]；MCU 虽低功耗但并行算力有限，难以满足深度模型的低延迟需求[15, 16]。相比之下，现场可编程门阵列（FPGA）以其可重构并行架构与对数据流的细粒度控制，成为实现 SNN 推理加速的有力平台[25, 26]。尽管 FPGA 的静态功耗通常高于MCU，但通过并行化与流水线化设计，energy-per-inference显著更优，并在延迟方面具有天然优势。同时，其设计理念与可移植性使其可作为面向未来类脑 ASIC 的过渡平台。由此，结合 FPGA 的可重构特性与 SNN 的事件驱动计算机制，可构建兼具低功耗、高并行与可扩展性的 EEG 情绪识别系统架构[18, 27]。

尽管 SNN 在事件驱动计算和稀疏激活层面具有显著优势，不过，其在处理高维、多通道 EEG 的表征能力上尚未完全成熟[27]。为了融合传统神经网络强大的特征表征能力和SNN高效的事件驱动计算模式，一种有效的策略是构建混合式架构。为此，本研究采用深度可分离卷积来构建一个轻量级的CNN特征提取前端，旨在以极低的计算成本从EEG信号中提取显著的时空特征；[28]随后，这些特征被编码为稀疏脉冲序列，交由SNN后端进行低功耗的分类决策，从而在性能与效率之间取得最佳平衡。

在设计一个有效的基于 SNN 的系统时，最后一个关键要素是编码方案，它负责将来自 CNN 的连续值特征转换为 SNN 所需的时间脉冲域。已有多种编码方法被提出，包括速率编码、人口编码、相位编码和首脉冲时间编码等。其中，速率编码通过脉冲发放频率来表示特征幅值，生物合理性较高，但需要较长时间窗口和大量脉冲，导致延迟增加和功耗上升[29]。人口编码依赖神经元群体的集体活动来表示信息，抗噪性强，但需要更多神经元参与，增加了硬件资源开销[30]。相位编码则通过脉冲与背景振荡信号的相位关系来表示信息，能捕捉时序特征，但在硬件实现中复杂度较高[31]。相比之下，TTFS（Time-to-First-Spike）编码将连续特征的幅值信息压缩为单次脉冲的发放时刻，从而在时间域上实现高度稀疏化：信息主要由脉冲发生的先后顺序与精确时间承载，而非长期的脉冲频率。这种表示显著减少了单位信息所需的脉冲总数与激活窗口长度，从而在实时性和动态能耗上带来明显优势，尤其适合对延迟和能耗敏感的边缘 SNN 部署[32,33]。

综上所述，尽管SNN、高效卷积和硬件加速都是活跃的研究领域，但本文旨在解决将这些元素协同设计成一个整体系统的需求。我们提出了一个基于FPGA的轻量级EEG情绪识别系统，该系统将深度可分离卷积前端与基于TTFS的SNN后端集成在一起。本研究的主要贡献如下：

[1] X. Li, Y. Zhang, P. Tiwari, et al., “EEG based emotion recognition: A tutorial and review,” *ACM Comput. Surv.*, vol. 55, no. 4, pp. 1–57, 2022.

[2] R. Pillalamarri and U. Shanmugam, “A review on EEG-based multimodal learning for emotion recognition,” *Artif. Intell. Rev.*, vol. 58, no. 5, p. 131, 2025.

[3] X. Li, D. Song, P. Zhang, et al., “Exploring EEG features in cross-subject emotion recognition,” *Front. Neurosci.*, vol. 12, p. 162, 2018.

[4] A. Y. Begum, E. E. Lawrence, M. Saravanan, et al., “Advanced biosignal processing and emotion recognition through artificial intelligence,” in *Applied Mathematical Modeling for Biomedical Robotics and Wearable Devices*. Academic Press, 2026, pp. 59–78.

[5] F. Tian, et al., “The three-lead EEG sensor: Introducing an EEG-assisted depression diagnosis system based on ant lion optimization,” *IEEE Trans. Biomed. Circuits Syst.*, vol. 17, no. 6, pp. 1305–1318, 2023.

[6] J. Cheng, M. Chen, C. Li, et al., “Emotion recognition from multi-channel EEG via deep forest,” *IEEE J. Biomed. Health Inform.*, vol. 25, no. 2, pp. 453–464, 2020.

[7] V. J. Lawhern, A. J. Solon, N. R. Waytowich, et al., “EEGNet: a compact convolutional neural network for EEG-based brain–computer interfaces,” *J. Neural Eng.*, vol. 15, no. 5, p. 056013, 2018.

[8] R. T. Schirrmeister, J. T. Springenberg, L. D. J. Fiederer, et al., “Deep learning with convolutional neural networks for EEG decoding and visualization,” *Hum. Brain Mapp.*, vol. 38, no. 11, pp. 5391–5420, 2017.

[9] A. Seal, S. R. et al., “DeprNet: A deep convolution neural network framework for detecting depression using EEG,” *IEEE Trans. Instrum. Meas.*, vol. 70, pp. 1–13, 2021.

[10] S. Alhagry, A. A. Fahmy and R. A. El-Khoribi, “Emotion recognition based on EEG using LSTM recurrent neural network,” *Int. J. Adv. Comput. Sci. Appl.*, vol. 8, no. 10, 2017.

[11] K. Devarajan, S. Ponnan and S. Perumal, “Enhancing emotion recognition through multi-modal data fusion and graph neural networks,” *Intelligence-Based Medicine*, p. 100291, 2025.

[12] D. Pan, H. Zheng, F. Xu, et al., “MSFR-GCN: A multi-scale feature reconstruction graph convolutional network for EEG emotion and cognition recognition,” *IEEE Trans. Neural Syst. Rehabil. Eng.*, vol. 31, pp. 3245–3254, 2023.

[13] H. Barki, N. D. Mai and W. Y. Chung, “Optimized XGBoost for multimodal affective state classification using in-ear PPG and behind-the-ear EEG signals,” *IEEE J. Biomed. Health Inform.*, 2025.

[14] X. Yi, “Energy-efficient EEG-based epileptic seizure detection: A deep learning-based spiking neural network approach,” *Procedia Comput. Sci.*, vol. 266, pp. 908–915, 2025.

[15] J. Lin, W.-M. Chen, Y. Lin, et al., “MCUNet: Tiny deep learning on IoT devices,” in *Adv. Neural Inf. Process. Syst.*, vol. 33, 2020, pp. 11711–11722.

[16] R. Sanchez-Iborra and A. F. Skarmeta, “TinyML-enabled frugal smart objects: Challenges and opportunities,” *IEEE Circuits Syst. Mag.*, vol. 20, no. 3, pp. 4–18, 2020.

[17] W. Maass, “Networks of spiking neurons: the third generation of neural network models,” *Neural Netw.*, vol. 10, no. 9, pp. 1659–1671, 1997.

[18] X. Zhang, J. Zhang, H. Huang, et al., “An Asynchronous RISC-V-based SNN Processor with Custom ISA Extensions for Programmable On-Chip Learning,” in *Proc. 29th IEEE Int. Symp. Asynchronous Circuits Syst. (ASYNC)*, IEEE, 2025, pp. 1–8.

[19] J. Bartels, O. Gallou, H. Ito, et al., “An event-driven neural network for monitoring of epileptic seizures on low-power neuromorphic hardware,” *bioRxiv*, 2024.

[20] N. Kumar, G. Tang, R. Yoo, et al., “Decoding EEG with spiking neural networks on neuromorphic hardware,” *Trans. Mach. Learn. Res.*, 2022.

[21] W. Alzhrani, M. Doborjeh, Z. Doborjeh, et al., “Emotion recognition and understanding using EEG data in a brain-inspired spiking neural network architecture,” in *Proc. 2021 Int. Joint Conf. Neural Netw. (IJCNN)*, IEEE, 2021, pp. 1–9.

[22] Z. Aalam, S. Aziz, K. L. Lew, et al., “Real-Time Emotion Detection Using Artificial Intelligence: A Review,” *Int. J. Robot. Autom. Sci.*, vol. 7, no. 1, pp. 104–110, 2025.

[23] S. Mittal, “A survey of techniques for approximate computing,” *ACM Comput. Surv. (CSUR)*, vol. 48, no. 4, pp. 1–33, 2016.

[24] A. Reuther, P. Michaleas, M. Jones, et al., “Survey of machine learning accelerators,” in *Proc. 2020 IEEE High Performance Extreme Computing Conf. (HPEC)*, 2020, pp. 1–12.

[25] V. Sze, Y.-H. Chen, T.-J. Yang, et al., “Efficient processing of deep neural networks: A tutorial and survey,” *Proc. IEEE*, vol. 105, no. 12, pp. 2295–2329, 2017.

[26] K. Guo, S. Zeng, J. Yu, et al., “A survey of FPGA-based neural network inference accelerators,” *ACM Trans. Reconfig. Technol. Syst. (TRETS)*, vol. 12, no. 1, pp. 1–26, 2019.

[27] S. Liu, H. Chu, Y. Feng, et al., “PicoSleepNet: An ultra lightweight sleep stage classification by spike neural network using single-channel EEG signal,” *IEEE J. Biomed. Health Inform.*, 2025.

[28] A. G. Howard, M. Zhu, B. Chen, et al., “MobileNets: Efficient convolutional neural networks for mobile vision applications,” *arXiv preprint arXiv:1704.04861*, 2017.

[29] A. A. M. Andrew, “Spiking neuron models: Single neurons, populations, plasticity,” *Kybernetes*, vol. 32, no. 7/8, 2003.

[30] C. Eliasmith and C. H. Anderson, *Neural engineering: Computation, representation, and dynamics in neurobiological systems*. MIT Press, 2003.

[31] C. Kayser, M. A. Montemurro, N. K. Logothetis, et al., “Spike-phase coding boosts and stabilizes information carried by spatial and temporal spike patterns,” *Neuron*, vol. 61, no. 4, pp. 597–608, 2009.

[32] H. Mostafa, “Supervised learning based on temporal coding in spiking neural networks,” *IEEE Trans. Neural Netw. Learn. Syst.*, vol. 29, no. 7, pp. 3227–3235, 2017.

[33] M. Zhang, S. Wang, J. Wu, et al., “Toward energy-efficient spike-based deep reinforcement learning with temporal coding,” *IEEE Comput. Intell. Mag.*, vol. 20, no. 2, pp. 45–57, 2025.



## 2. METHODOLOGY AND ALGORITHM

当前，可穿戴 EEG 情绪识别设备的主要挑战在于传统深度神经网络的计算范式与 EEG 信号的生理特性存在根本不匹配。前者依赖密集且同步的矩阵运算，而后者本质上表现为稀疏、事件驱动的神经活动。这种差异导致现有模型难以在功耗和算力受限的设备上高效运行。为实现低功耗、低延迟的边缘情绪识别系统，需要一种既能充分捕获生物信号时空特征，又能在资源受限硬件上高效执行的新型计算架构。

本研究提出一种面向硬件优化的轻量级混合神经网络，将高效的时空特征提取与事件驱动的脉冲计算相结合，以弥合算法结构与信号特性之间的差距。==如图所示==，网络前端采用深度可分离卷积结构，用于高效提取 EEG 信号的时空特征并显著降低参数量和乘加复杂度。中间部分引入一种硬件友好的无除法 TTFS（time-to-first-spike）时间编码模块，将连续波形映射为稀疏脉冲序列，从而适配事件驱动计算机制。后端由基于TTFS编码的脉冲神经网络完成分类决策，在保持竞争性分类精度的同时，实现低功耗和低延迟推理。该架构在设计中充分考虑 FPGA 与可穿戴设备的实现约束，为实时、能效优化的 EEG 情绪识别提供了一种可行的技术途径。

### A.Neuron Model and TTFS Coding

脑电（EEG）信号作为一种典型的非平稳时序信号，蕴含了大量与情绪状态相关的动态信息，其时域波动与事件触发过程具有显著的时间依赖性。脉冲神经网络（Spiking Neural Network, SNN）通过膜电位积累、阈值触发与事件驱动的计算机制，能够以更生物启发的方式表达神经活动的时序特征，因而在EEG等时间敏感型任务中表现出潜在优势。

在SNN的设计中，神经元模型是定义时域动态与信息编码方式的关键。当前常用的脉冲神经元模型主要包括 Leaky Integrate-and-Fire (LIF) []、Izhikevich []、Hodgkin–Huxley (HH) [] 以及 Spike Response Model (SRM)[]。其中，HH模型能够精确刻画神经元膜电位的生理演化，被视为生物神经计算的黄金标准，但计算复杂度极高，难以部署在低功耗平台上。Izhikevich与SRM模型在生物真实性与计算效率之间取得平衡，但依然需要较高的资源开销。LIF 模型因其结构简洁、数学形式可离散化而成为工程实现中最常用的神经元模型。其膜电位随时间的演化可表示为

$V[t+1] = \alpha V[t] + I[t],$

其中，$\alpha = e^{-\Delta t / \tau} $为指数衰减因子，$I[t]$表示输入电流。这一形式在算法层面易于仿真，但在硬件实现中仍面临一定挑战：衰减项 $\alpha V[t]$ 需要在每个时间步执行一次乘法操作，而当网络规模较大时，大量乘法运算将占用可观的 DSP 资源或查找表，从而增加功耗并降低并行效率。尤其在 FPGA 或低功耗 SoC 等资源受限平台上，LIF 模型的指数衰减机制成为制约其实时部署与扩展能力的主要瓶颈。

为解决LIF等模型在计算和硬件实现上的局限性，并充分发挥SNN的稀疏计算优势，本研究在编码范式与神经元模型两个层面进行了协同设计。

<img src="%E8%AE%BA%E6%96%87.assets/image-20251028222808313.png" alt="image-20251028222808313" style="zoom:67%;" />

本研究采用的核心编码范式是首脉冲时间编码（Time-To-First-Spike, TTFS）。TTFS编码方式通过将更强的输入激转化为更早的脉冲发放时间，并且每个神经元在一个计算周期内最多只发放一个脉冲，实现了极致的脉冲稀疏性，确保了最低的理论功耗和最快的响应速度。此外，本文采用了B1脉冲神经元模型[]以契合该编码方式。B1模型的核心就是引入了一个级联时间窗（Cascading Time Window）机制，为TTFS编码提供了完美的硬件友好型实现框架。该模型的核心是将复杂的神经元动力学简化为一个分段线性的过程，省去了在硬件上实现成本高昂的指数运算与乘法衰减项。其动态特性由时间窗（Temporal Bounds）$[t_{\min}^{(n)}, t_{\max}^{(n)}]$ 划分为两个计算阶段。

网络的第 $n$ 层的时间窗 为$[t_{\min}^{(n)}, t_{\max}^{(n)}]$。每一层的$t_{\min}^{(n)}$被定义为上一层的$t_{\max}^{(n-1)}$，即 $t_{min}^{(n)} =^{def} t_{max}^{(n-1)}$。
其膜电位演化可描述为：
$$
\epsilon \frac{dV_i^{(n)}(t)}{dt} =
\begin{cases}
\sum_j W_{ij}^{(n)} H(t - t_j^{(n-1)}), & t < t_{\min}^{(n)} \quad \text{(积分阶段)} \\
1, & t_{\min}^{(n)} \le t \le t_{\max}^{(n)} \quad \text{(爬升阶段)}
\end{cases}
$$
其中，$\epsilon$ 为时间常数，$H(\cdot)$ 为亥维赛阶跃函数，$W_{ij}^{(n)}$ 为突触权重。

在 $t < t_{\min}^{(n)}$ 的时间区间内，神经元膜电位 $\frac{dV_i^{(n)}}{dt}$ 的斜率由加权输入脉冲 $\sum_j W_{ij}^{(n)} H(t - t_j^{(n-1)})$ 决定。随后，在 $t_{\min}^{(n)} \le t \le t_{\max}^{(n)}$ 的时间区间内，膜电位斜率 $\frac{dV_i^{(n)}}{dt}$ 被固定位1，以恒定的速率开始线性增长。

对于第 $n$ 层的神经元 $i$，其输出脉冲的时刻 $t_i^{(n)}$ 是基于上一层的输入 $t_j^{(n-1)}$ 和阈值 $\vartheta_i^{(n)}$计算得出的。由B1模型的膜电位动力学，可直接推导出该前向传播方程如式（1）所示：

$$
t_i^{(n)} = t_{\min}^{(n)} + \tau_c \vartheta_i^{(n)} - \sum_j W_{ij}^{(n)} \bigl( t_{\min}^{(n)} - t_j^{(n-1)} \bigr) \quad \text{(1)}
$$

若神经元i的脉冲发放时间 $t_i^{(n)}$ 超过本层的时间窗$t_{\max}^{(n)}$，该神经元便被视为未发放脉冲，在本计算周期内将保持沉默，不产生任何输出脉冲。

### B. Layer Structure

## 5. IMPLEMENTATION AND RESULTS

### 5.1 数据集、预处理和实验环境
### 5.2 模型性能分析
软件：不同模型架构的性能对比：准确率、精确率、召回率、F1分数等指标
混淆矩阵：各类情绪分类的预测结果
鲁棒性分析：加入不同强度的高斯噪声，模拟实际工作环境

### 5.3 硬件性能分析
FPGA的实际准确率
吞吐量
FPGA资源占用
量化分析：从32、16位、8位、6位到4位

## 6. CONCLUSION
### 6.1 研究总结
### 6.2 未来工作展望
