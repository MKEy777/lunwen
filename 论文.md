# Design of an Efficient TTFS-SNN-Based EEG Emotion Recognition System on Lightweight FPGA
基于 TTFS-SNN 的高效 EEG 情绪识别系统轻量 FPGA 实现
## 摘要
**关键词：** Spiking Neural Network (SNN)；Depthwise Separable Convolution；Energy-Efficient；Lightweight
## 1. INTRODUCTION
### 1.1 研究背景

+ 讲一下情绪和脑电信号的相关性、机器学习和深度学习的对比引出CNN部分。又因为缺少时序信息从而引出CNN。由于轻量化的需要，使用深度可分离卷积+基于TTFS的SNN，在保持高准确率的同时，弥补了CNN和SNN对不同层次的特征提取短板，并且做到了计算资源大量下降。

+ 情绪识别比抑郁症或癫痫等基于 EEG 的疾病分类更难，主要因为情绪标签主观且缺乏客观金标准、情绪是短时波动的状态而非稳定特征、情绪相关的脑电信号通常较弱且分散、个体间反应差异大且实验刺激/标注方式不统一，同时外周生理（心率、面肌、电导等）会混入 EEG 增加混杂噪声等原因，要取得较高的准确率往往要消耗大量资源，目前在各种边缘设备上尤其是FPGA平台的研究还十分欠缺。

### 
### 1.2 主要贡献
## 2. RELATED WORK
### 2.1 脉冲神经网络研究现状
### 2.2 深度可分离卷积研究进展
### 2.3 神经网络硬件加速技术
## 3. METHODOLOGY AND ALGORITHM
当前，主流的神经网络模型因其庞大的参数规模，难以直接部署于功耗和算力受限的可穿戴式、嵌入式设备。因此，轻量化网络设计的核心目标是在维持高精度的同时，最大限度地降低模型参数量与计算复杂度，从而使其在诸如现场可编程门阵列（FPGA）等资源有限的硬件平台上部署成为可能。
出于此目的，本研究致力于实现一种参数高效的脉冲神经网络（SNN）架构，旨在方便地部署于低功耗、低延迟的便携式设备上，用于实时脑电（EEG）情绪识别任务，并同时保持具有竞争力的分类精度。为实现此目标，我们提出了一种专为硬件优化设计的轻量级混合神经网络架构。该架构有机地结合了深度可分离卷积与脉冲神经网络，其核心组件包括：一个用于高效提取EEG信号时空特征的深度可分离卷积前端、一个硬件友好的无除法时间编码（TTFS）模块，以及一个负责分类决策的全连接SNN后端。
A.深度可分离卷积（Depthwise Separable Convolution）构成了本系统特征提取模块的核心，其设计旨在通过对标准卷积运算进行分解，以一种计算高效的方式，精细化地提取脑电（EEG）信号中蕴含的多维度时空特征。此架构不仅显著降低了模型的参数量与运算复杂度，更重要的是，其固有的结构特性为在资源受限的FPGA平台上实现高性能硬件加速提供了理论基础。
该模块的设计遵循两个核心步骤：深度卷积（Depthwise Convolution）与逐点卷积（Pointwise Convolution）。首先，深度卷积在输入的各个特征通道上独立地进行空间滤波，其目的在于捕捉每个通道内部的局部相关性与模式，例如特定电极附近信号的时域动态。随后，逐点卷积利用1x1的卷积核对深度卷积的输出进行线性组合，从而实现跨通道的信息融合与特征抽象。这种分解策略，将空间特征提取与通道特征整合解耦，相较于标准卷积在一次操作中同时处理二者，极大地减少了乘累加运算的需求。
该分解策略的硬件友好性体现在多个层面。首先，其运算量相较于标准卷积呈指数级降低。对于一个`KxK`的标准卷积，其计算成本约为$O(K^2 \cdot C_{in} \cdot C_{out})$，而深度可分离卷积的成本降至约$O(K^2 \cdot C_{in} + C_{in} \cdot C_{out})$，可节省数倍的乘累加（MAC）运算，从而显著减少对FPGA上宝贵的DSP（数字信号处理）或逻辑资源的需求。

其次，整个特征提取器由固定模式的模块串联而成，形成了规整、重复的结构化数据流，这非常适合在FPGA上构建深度流水线（Pipeline）。数据能够无阻塞地流经一系列处理单元，从而实现极高的处理吞-吐量。此外，通过采用大于1的步长（stride）进行卷积，可在提取特征的同时高效地对特征图进行降采样，显著减少后续层需要处理和缓存的数据量，进而节约片上缓存（BRAM）资源并降低功耗。

最后，该设计体现了算法与硬件的协同优化思想，特别是在算子替换方面。例如，在需要对数据进行归一化时，系统避免了在FPGA上实现昂贵且低效的通用浮点除法，而是通过将除数约束为2的整数次幂，使该操作在硬件层面可由一个高效、零开销的逻辑位移（Bit-Shift）操作替代。(具体见HARDWARE ARCHITECTURE)这一系列设计共同确保了模型在硬件上的高效运行。
为进一步增强模型的表达能力与训练稳定性，该模块在卷积层后集成了批标准化（Batch Normalization）与非线性激活函数（ReLU）。批标准化旨在缓解内部协变量偏移问题，加速网络收敛，而激活函数则为模型引入了必要的非线性表达能力。这一系列设计在后续可以通过参数融合优化的批标准化和利用ReLU的硬件原生性共同构成了一个高效、低功耗的特征提取前端，为脉冲神经网络（SNN）模块提供了高质量的输入特征，是整个系统实现高能效比的关键。
### 3.3 TTFS编码机制设计
将人工神经网络（ANN）中的连续激活值转换为脉冲神经网络（SNN）中的离散脉冲序列，是连接这两种计算范式的关键步骤，也是决定系统整体能效的核心环节。SNN的低功耗潜力源于其事件驱动（Event-Driven）的计算模式，即只有在接收到脉冲时才进行计算。因此，一个高效的编码机制应当以最少的脉冲数量来承载最丰富的信息，从而最大化计算的稀疏性，降低系统的动态功耗。
在众多编码方案中，时间编码，特别是首脉冲时间编码（Time-To-First-Spike, TTFS），相比于速率编码（Rate Coding）等方法，展现出在延迟和功耗上的显著优势。速率编码需要在一个较长的时间窗口内通过累积脉冲频率来表征信息强度，这不仅引入了显著的计算延迟，而且高强度的信号会产生密集的脉冲，增加了系统的计算开销。相比之下，TTFS编码将信息完全编码在单个脉冲的精确发放时间上，一旦脉冲发出，信息即被传递。这种“单一脉冲”的编码策略实现了极致的脉冲稀疏性，确保了最低的理论功-耗和最快的响应速度，使其成为构建轻量级、低延迟SNN系统的理想选择。
在本研究中，我们设计并实现了一种专为硬件优化的无除法TTFS编码机制，作为连接前级卷积模块与SNN的桥梁。该机制的核心创新在于，它以硬件成本极低的二次幂缩放（Power-of-Two Scaling）完全替代了传统归一化操作中资源开销巨大的浮点除法运算。其具体流程如下：首先，编码器在训练阶段通过动量更新机制，持续跟踪输入激活值的动态范围（即最大值和最小值）。随后，基于该动态范围计算出一个最优的、为2的整数次幂的缩放因子。输入激活值在减去最小值后，将被该缩放因子归一化——这一步在硬件上可由一次高效的逻辑位移（Bit-Shift）操作完成。最后，经过钳位处理的归一化结果被线性映射为一个精确的脉冲时间序列，其中激活值越高，脉冲发放时间越早。通过该机制，系统不仅确保了编码过程的实时性和低延迟特性，更实现了从连续激活值到离散脉冲的平滑转换，为后续SNN模块提供了生物学上合理的、且硬件实现高度友好的时域输入信号。
### 3.4 SNN模块设计
SNN模块基于多层全连接脉冲神经元构建，集成于统一的模型容器中，负责处理TTFS编码后的时序信号，实现情绪类别的最终判别。各脉冲层包括权重矩阵和偏差参数，前向传播逻辑区分隐藏层与输出层：隐藏层计算阈值并钳位输出，同时记录最小有效脉冲以动态调节时间窗；输出层则融合累积潜力和时序偏差，实现分类映射。该模块支持逐层添加组件，包括编码器和正则化层，权重采用均匀初始化以促进稳定训练。时间参数通过级联设置机制传播，结合动态扩展策略增强网络的表达能力。该设计强调SNN的低功耗潜力，通过时序编码捕捉EEG信号的微妙动态，为实时情绪识别提供了高效的计算范式。
本研究中的SNN模块是负责处理时序编码信号并执行最终情绪分类的核心计算单元。该模块的架构基于一种特定的脉冲神经元模型，并集成在一个支持动态调整的多层全连接网络中，旨在高效地从输入脉冲序列中提取特征并完成判别任务。
3.4.1 B1脉冲神经元模型
本模块的基础构建单元是Stanojevic等人提出的B1脉冲神经元模型 。该模型的核心在于其独特的膜电位（Membrane Potential）动力学机制，该机制被划分为两个连续的阶段。在第一阶段，神经元对输入脉冲进行积分，但其自身的基准电压斜率被设定为零 (A i(n)=0) 。当时间进入第二阶段后，其膜电位的上升斜率切换为一个固定的正常数，并归一化为1 (Bi(n)=1) 。这种分阶段的、后期斜率恒定的设计，在理论上建立了一种SNN与等效ReLU网络之间的“恒等映射”关系 。
3.4.2 网络架构与前向传播机制
基于B1神经元模型，我们构建了一个全连接的前馈SNN网络。该网络由多个隐藏层和一个输出层堆叠而成，负责对TTFS编码器产生的脉冲时间向量进行逐层处理。网络中不同层次的神经元承担着不同的计算角色：
+ 隐藏层：时域非线性变换
隐藏层的功能是对输入的脉冲时间模式进行非线性变换，以生成一组在更高维度上更具抽象意义的新脉冲时间，作为下一层的输入。具体而言，一个神经元的输出脉冲时间由其膜电位达到一个可训练阈值的时刻决定。其核心计算是对输入的相对脉冲时间（即输入脉冲时刻与当前层时间窗起点的差值）进行加权求和，该结果决定了达到阈值的延迟。此过程在时域上完成了一次高效的非线性特征提取。
+ 输出层：时域证据积分
与隐藏层不同，输出层神经元不发放脉冲，而是作为“读出单元”（Readout Unit） 。它们在整个时间窗口内对来自最后一个隐藏层的脉冲进行加权积分，将时域的稀疏信息转换回幅度域。每个输出神经元最终的膜电位值是一个实数值（Logit），直接代表了模型对于输入样本属于各个情绪类别的置信度，从而将SNN的脉冲计算与最终的分类决策无缝衔接。

3.4.3 自适应时间窗调整机制
在TTFS编码范式中，时间窗$(\Delta t = t_{\max} - t_{\min})$ 是一个核心超参数，它不仅定义了神经元编码的动态范围，也直接影响了信息表示的分辨率。在深度网络训练过程中，各层激活值的统计分布是动态变化的，采用一个静态、预设的时间窗会严重制约模型的学习与表达能力。一个过窄的窗口会导致信息饱和（即大量神经元的脉冲时间被钳位在 $(t_{\max})$），而一个过宽的窗口则会浪费编码的"带宽"，降低编码效率。

为解决这一问题，我们引入了一种在线的、基于活动依赖的自适应时间窗调整机制。该机制在网络训练过程中实时监控各隐藏层的脉冲发放动态，并据此对后续层级的时间窗进行动态重校准。具体而言，在每个训练批次处理完毕后，系统会记录该层在所有样本中实际产生的最早脉冲时间 $(\min(t_i^{(n)}))$。

该层的结束时间$ (t_{\max}^{(n)})$ 会依据此信息进行更新，以确保所有脉冲都远离时间窗的边界。随后，下一层的时间窗起始点 $(t_{\min}^{(n+1)}) $会被设定为当前层更新后的结束点$ (t_{\max, \text{new}}^{(n)})$，从而实现层与层之间时间窗的级联更新。若监测到某一层产生了非常早的脉冲，表明该层的激活值动态范围较大，该机制便会相应地扩展后续层的时间窗，以提供更充足的编码空间。

通过这种自适应调整，系统能够确保时间编码资源始终被高效地分配和利用，动态地将有限的时间分辨率匹配给最关键的激活值区间。这不仅有效避免了因编码范围不匹配而导致的信息损失和性能瓶颈，更显著增强了模型整体的表达能力与训练过程的鲁棒性。

技术实现细节
自适应时间窗调整机制的具体实现包含以下关键步骤：

脉冲时间监测：在每个训练迭代中，系统实时记录各隐藏层神经元产生的脉冲时间分布，提取统计特征包括最小值、最大值、均值和方差。

动态范围计算：基于监测到的脉冲时间分布，计算当前层的有效动态范围 $(\mathcal{D}^{(n)} = t_{\max}^{(n)} - t_{\min}^{(n)})$，并评估其与预设阈值的偏离程度。

窗口边界调整：根据动态范围的变化，采用以下更新规则调整时间窗边界： $[ t_{\max, \text{new}}^{(n)} = t_{\max}^{(n)} + \alpha \cdot (\mathcal{D}{\text{target}} - \mathcal{D}^{(n)}) ]$ 其中 $(\alpha)$ 为学习率，$(\mathcal{D}{\text{target}}) $为目标动态范围。

层间传播机制：将调整后的时间窗边界传递至下一层：$ [ t_{\min}^{(n+1)} = t_{\max, \text{new}}^{(n)} ] [ t_{\max}^{(n+1)} = t_{\min}^{(n+1)} + \mathcal{D}_{\text{target}} ]$

该机制的实现充分考虑了硬件资源的约束，采用了轻量级的计算策略，确保在FPGA平台上能够高效运行。通过这种自适应调整，系统不仅提高了编码效率，还增强了模型对输入信号变化的适应能力。
## 4. HARDWARE ARCHITECTURE
### 4.1 FPGA整体架构
本系统的FPGA实现采用了GALS（Globally Asynchronous Locally Synchronous）双时钟域设计，模块内部集成时钟门控机制，以优化功耗和时序性能。整体架构由顶层模块、深度可分离卷积流处理模块、SNN处理模块以及跨域同步模块构成。通过全流水线处理路径，实现了数据从输入到输出的高效传输与计算。顶层模块协调各子系统，利用双翻转同步器处理起始信号、脉冲握手及完成标志的跨域通信，确保异步接口的可靠性。该架构的创新在于其对异构计算的适应性，深度可分离卷积域注重并行加速，SNN域强调时序脉冲处理，从而在有限资源下实现了系统级优化，为嵌入式EEG应用提供了可移植的硬件框架。
### 4.2 深度可分离卷积模块
深度可分离卷积模块采用流式处理架构，实现硬件级加速。输入特征通过块随机访问存储器（BRAM）接口加载，内部利用多路ROM同步模块，按通道拆分存储卷积核、权重、偏置及缩放参数，确保参数访问的低延迟。卷积流程分层展开：深度卷积捕捉通道内模式，点卷积实现跨通道融合，支持可配置步长以适应特征尺度变换。输出经TTFS编码单元转换为脉冲序列，使用移位缩放机制避免除法运算。有限状态机（FSM）控制像素级流水，包括空闲、计算及发送阶段，与下游模块的异步握手接口无缝对接。该模块的设计突出资源效率，通过常量优化和串行输出，提升了在FPGA上的部署适用性。
### 4.3 SNN 模块
SNN模块实现多层脉冲网络，采用FSM驱动的阶段性计算流程，包括累加、桥接及最终决策。各层利用ROM同步加载权重和参数，RAM同步维护中间状态，支持并行神经元访问。桥接单元将层间扁平化结果转换为串行脉冲流，支持无效脉冲过滤以减少传输冗余。输入接口接收上游脉冲信号，输出层集成ArgMax单元提取最大潜力类别。时钟门控逻辑仅在对应状态激活子模块，显著降低动态功耗。内存接口设计强调数据一致性，确保权重和状态的高效复用。该模块的架构优化聚焦于时序精确性和低延迟，体现了SNN在FPGA上的生物仿真优势，为EEG情绪识别的嵌入式实现提供了坚实基础。
## 5. IMPLEMENTATION AND RESULTS
### 5.1 数据集、预处理和实验环境
### 5.2 模型性能分析
软件：不同模型架构的性能对比：准确率、精确率、召回率、F1分数等指标
混淆矩阵：各类情绪分类的预测结果
鲁棒性分析：加入不同强度的高斯噪声，模拟实际工作环境
### 5.3 硬件性能分析
FPGA的实际准确率
吞吐量
FPGA资源占用
量化分析：从32、16位、8位、6位到4位
## 6. CONCLUSION
### 6.1 研究总结
### 6.2 未来工作展望
