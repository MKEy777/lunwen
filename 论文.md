# Design of an Efficient TTFS-SNN-Based EEG Emotion Recognition System on Lightweight FPGA
基于 TTFS-SNN 的高效 EEG 情绪识别系统轻量 FPGA 实现
## 摘要
**关键词：** Spiking Neural Network (SNN)；Depthwise Separable Convolution；Energy-Efficient；Lightweight
## 1. INTRODUCTION
### 1.1 研究背景

+ 讲一下情绪和脑电信号的相关性、机器学习和深度学习的对比引出CNN部分。又因为缺少时序信息从而引出CNN。由于轻量化的需要，使用深度可分离卷积+基于TTFS的SNN，在保持高准确率的同时，弥补了CNN和SNN对不同层次的特征提取短板，并且做到了计算资源大量下降。

+ 情绪识别比抑郁症或癫痫等基于 EEG 的疾病分类更难，主要因为情绪标签主观且缺乏客观金标准、情绪是短时波动的状态而非稳定特征、情绪相关的脑电信号通常较弱且分散、个体间反应差异大且实验刺激/标注方式不统一，同时外周生理（心率、面肌、电导等）会混入 EEG 增加混杂噪声等原因，要取得较高的准确率往往要消耗大量资源，目前在各种边缘设备上尤其是FPGA平台的研究还十分欠缺。

### 
### 1.2 主要贡献
## 2. RELATED WORK
### 2.1 脉冲神经网络研究现状
### 2.2 深度可分离卷积研究进展
### 2.3 神经网络硬件加速技术
## 3. METHODOLOGY AND ALGORITHM
当前，主流的神经网络模型因其庞大的参数规模，难以直接部署于功耗和算力受限的可穿戴式、嵌入式设备。因此，轻量化网络设计的核心目标是在维持高精度的同时，最大限度地降低模型参数量与计算复杂度，从而使其在诸如现场可编程门阵列（FPGA）等资源有限的硬件平台上部署成为可能。
出于此目的，本研究致力于实现一种参数高效的脉冲神经网络（SNN）架构，旨在方便地部署于低功耗、低延迟的便携式设备上，用于实时脑电（EEG）情绪识别任务，并同时保持具有竞争力的分类精度。为实现此目标，我们提出了一种专为硬件优化设计的轻量级混合神经网络架构。该架构有机地结合了深度可分离卷积与脉冲神经网络，其核心组件包括：一个用于高效提取EEG信号时空特征的深度可分离卷积前端、一个硬件友好的无除法时间编码（TTFS）模块，以及一个负责分类决策的全连接SNN后端。
A.深度可分离卷积（Depthwise Separable Convolution）构成了本系统特征提取模块的核心，其设计旨在通过对标准卷积运算进行分解，以一种计算高效的方式，精细化地提取脑电（EEG）信号中蕴含的多维度时空特征。此架构不仅显著降低了模型的参数量与运算复杂度，更重要的是，其固有的结构特性为在资源受限的FPGA平台上实现高性能硬件加速提供了理论基础。
该模块的设计遵循两个核心步骤：深度卷积（Depthwise Convolution）与逐点卷积（Pointwise Convolution）。首先，深度卷积在输入的各个特征通道上独立地进行空间滤波，其目的在于捕捉每个通道内部的局部相关性与模式，例如特定电极附近信号的时域动态。随后，逐点卷积利用1x1的卷积核对深度卷积的输出进行线性组合，从而实现跨通道的信息融合与特征抽象。这种分解策略，将空间特征提取与通道特征整合解耦，相较于标准卷积在一次操作中同时处理二者，极大地减少了乘累加运算的需求。
该分解策略的硬件友好性体现在多个层面。首先，其运算量相较于标准卷积呈指数级降低。对于一个`KxK`的标准卷积，其计算成本约为$O(K^2 \cdot C_{in} \cdot C_{out})$，而深度可分离卷积的成本降至约$O(K^2 \cdot C_{in} + C_{in} \cdot C_{out})$，可节省数倍的乘累加（MAC）运算，从而显著减少对FPGA上宝贵的DSP（数字信号处理）或逻辑资源的需求。

其次，整个特征提取器由固定模式的模块串联而成，形成了规整、重复的结构化数据流，这非常适合在FPGA上构建深度流水线（Pipeline）。数据能够无阻塞地流经一系列处理单元，从而实现极高的处理吞-吐量。此外，通过采用大于1的步长（stride）进行卷积，可在提取特征的同时高效地对特征图进行降采样，显著减少后续层需要处理和缓存的数据量，进而节约片上缓存（BRAM）资源并降低功耗。

最后，该设计体现了算法与硬件的协同优化思想，特别是在算子替换方面。例如，在需要对数据进行归一化时，系统避免了在FPGA上实现昂贵且低效的通用浮点除法，而是通过将除数约束为2的整数次幂，使该操作在硬件层面可由一个高效、零开销的逻辑位移（Bit-Shift）操作替代。(具体见HARDWARE ARCHITECTURE)这一系列设计共同确保了模型在硬件上的高效运行。
为进一步增强模型的表达能力与训练稳定性，该模块在卷积层后集成了批标准化（Batch Normalization）与非线性激活函数（ReLU）。批标准化旨在缓解内部协变量偏移问题，加速网络收敛，而激活函数则为模型引入了必要的非线性表达能力。这一系列设计在后续可以通过参数融合优化的批标准化和利用ReLU的硬件原生性共同构成了一个高效、低功耗的特征提取前端，为脉冲神经网络（SNN）模块提供了高质量的输入特征，是整个系统实现高能效比的关键。
### 3.3 TTFS编码机制设计
将人工神经网络（ANN）中的连续激活值转换为脉冲神经网络（SNN）中的离散脉冲序列，是连接这两种计算范式的关键步骤，也是决定系统整体能效的核心环节。SNN的低功耗潜力源于其事件驱动（Event-Driven）的计算模式，即只有在接收到脉冲时才进行计算。因此，一个高效的编码机制应当以最少的脉冲数量来承载最丰富的信息，从而最大化计算的稀疏性，降低系统的动态功耗。
在众多编码方案中，时间编码，特别是首脉冲时间编码（Time-To-First-Spike, TTFS），相比于速率编码（Rate Coding）等方法，展现出在延迟和功耗上的显著优势。速率编码需要在一个较长的时间窗口内通过累积脉冲频率来表征信息强度，这不仅引入了显著的计算延迟，而且高强度的信号会产生密集的脉冲，增加了系统的计算开销。相比之下，TTFS编码将信息完全编码在单个脉冲的精确发放时间上，一旦脉冲发出，信息即被传递。这种“单一脉冲”的编码策略实现了极致的脉冲稀疏性，确保了最低的理论功-耗和最快的响应速度，使其成为构建轻量级、低延迟SNN系统的理想选择。
在本研究中，我们设计并实现了一种专为硬件优化的无除法TTFS编码机制，作为连接前级卷积模块与SNN的桥梁。该机制的核心创新在于，它以硬件成本极低的二次幂缩放完全替代了传统归一化操作中资源开销巨大的浮点除法运算。其具体流程如下：首先，编码器在训练阶段通过动量更新机制，持续跟踪输入激活值的动态范围（即最大值和最小值）。随后，基于该动态范围计算出一个最优的、为2的整数次幂的缩放因子。输入激活值在减去最小值后，将被该缩放因子归一化——这一步在硬件上可由一次高效的逻辑位移操作完成。为确保编码的有效性，归一化后的激活值会被严格地钳位到 [0, 1] 区间内。最后，该处于 [0, 1] 范围内的归一化结果被线性映射为一个精确的脉冲时间序列，其中激活值越高，脉冲发放时间越早。通过该机制，系统不仅确保了编码过程的实时性和低延迟特性，更实现了从连续激活值到离散脉冲的平滑转换，为后续SNN模块提供了生物学上合理的、且硬件实现高度友好的时域输入信号。
### 3.4 SNN模块设计
SNN模块基于多层全连接脉冲神经元构建，集成于统一的模型容器中，负责处理TTFS编码后的时序信号，实现情绪类别的最终判别。各脉冲层包括权重矩阵和偏差参数，前向传播逻辑区分隐藏层与输出层：隐藏层计算阈值并钳位输出，同时记录最小有效脉冲以动态调节时间窗；输出层则融合累积潜力和时序偏差，实现分类映射。该模块支持逐层添加组件，包括编码器和正则化层，权重采用均匀初始化以促进稳定训练。时间参数通过级联设置机制传播，结合动态时间窗机制增强网络的表达能力。该设计发挥了SNN的低功耗潜力，通过时序编码捕捉EEG信号的动态特征，为实时情绪识别提供了高效的计算范式。

3.4.1 B1脉冲神经元模型
本模块的基础构建单元是Stanojevic等人提出的B1脉冲神经元模型 。该模型的核心在于其独特的膜电位动力学机制，该机制被划分为两个连续的阶段。描述该动力学的公式如下：
$$\epsilon\frac{dV_{i}^{(n)}}{dt} = 
\begin{cases} 
\sum_{j}W_{ij}^{(n)}H(t-t_{j}^{(n-1)}) & \text{for } t < t_{\min}^{(n)} \\
1 & \text{for } t_{\min}^{(n)} \le t \le t_{\max}^{(n)}
\end{cases}$$
其中，$V_i(n)$ 是神经元膜电位，$\epsilon$ 是一个时间常数，$W_{ij}(n)$ 是突触权重，$H(\cdot)$ 是亥维赛阶跃函数。在第一阶段，神经元对输入脉冲进行积分，但其自身的基准电压斜率被设定为零 ($A_i(n) = 0$)。当时间进入第二阶段后，其膜电位的上升斜率切换为一个固定的正常数，并归一化为1 ($B_i(n) = 1$)。

3.4.2 网络架构与前向传播机制
本模块的整体架构是一个全连接的前馈网络，其核心特点在于信息处理在时间维度上的级联划分。网络的每一层都在一个专属的、连续的时间窗内进行运算。在初始化阶段，输入层的时间窗被编码为[0,1]，后续时间窗由$t_{\min}^{(n+1)}=t_{\max}^{(n)}$定义，区间差值为1. 这种设计确保了信号能够有序地、逐层地在时间维度上传播。在训练过程中，各层时间窗的边界会通过自适应时间窗调整机制进行动态优化。
隐藏层的功能是对输入的脉冲时间向量进行非线性变换，以生成下一层所需的新脉冲时间向量。对于第 $n$ 层的神经元 $i$，其输出脉冲时刻 $t_i^{(n)}$ 根据以下公式计算得出：
$$
t_i^{(n)} = t_{\min}^{(n)} + \tau_c \, \vartheta_i^{(n)} - \sum_j W_{ij}^{(n)} \bigl( t_{\min}^{(n)} - t_j^{(n-1)} \bigr)
$$
此计算将输入的相对脉冲时间模式映射为新的输出脉冲时间。  
与隐藏层不同，输出层作为非脉冲“读出单元” ，其职责是在其指定的时间窗口内，持续积分由最后一个隐藏层传入的脉冲所产生的影响 。每个到达的脉冲都会对其膜电位进行一次加权更新。在时间窗结束时读出神经元内部累积的总电位即为最终的输出值（Logit）。对于输出神经元 i，其在读出时刻的最终电位值 Li可由以下公式计算得出：
$$
L_i = \sum_j W_{ji} \bigl( t_{\min}^{(N)} - t_j^{(N)} \bigr)+\text{bias}_i
$$
此过程通过时域稀疏解码，将时间域信息转换回幅度域的决策值。


### 3.4.3 自适应时间窗调整机制
在TTFS编码范式中，时间窗$(\Delta t = t_{\max} - t_{\min})$ 是一个核心超参数，它不仅定义了神经元编码的动态范围，也直接影响了信息表示的分辨率。在深度网络训练过程中，各层激活值的统计分布是动态变化的，采用一个静态、预设的时间窗会严重制约模型的学习与表达能力。一个过窄的窗口会导致信息饱和（即大量神经元的脉冲时间被钳位在 $t_{\max}$），而一个过宽的窗口则会浪费编码的"带宽"，降低编码效率。
为解决这一问题，我们引入了一种在线的、基于活动依赖的自适应时间窗调整机制。该机制在网络训练过程中实时监控各隐藏层的脉冲发放动态，并据此对后续层级的时间窗进行动态重校准。具体而言，在每个训练批次处理完毕后，系统会记录该层在所有样本中实际产生的最早脉冲时间 $(\min(t_i^{(n)}))$ 。该层的结束时间 $(t_{\max}^{(n)})$ 会依据此信息进行更新，以确保所有脉冲都远离时间窗的边界。随后，下一层的时间窗起始点 $(t_{\min}^{(n+1)})$ 会被设定为当前层更新后的结束点 $(t_{\max, \text{new}}^{(n)})$，从而实现层与层之间时间窗的级联更新 。若监测到某一层产生了非常早的脉冲，表明该层的激活值动态范围较大，该机制便会相应地扩展后续层的时间窗，以提供更充足的编码空间。

通过这种自适应调整，系统能够确保时间编码资源始终被高效地分配和利用，动态地将有限的时间分辨率匹配给最关键的激活值区间。这不仅有效避免了因编码范围不匹配而导致的信息损失和性能瓶颈，更显著增强了模型整体的表达能力与训练过程的鲁棒性。

#### 技术实现细节
自适应时间窗调整机制的具体实现是一种乘性增益控制机制，包含以下关键步骤：

* 脉冲时间监测：在每个训练迭代中，系统实时记录当前层在所有样本中产生的最早脉冲时间 $(\min(t_i^{(n)}))$。

* 窗口边界调整：该机制采用乘性增益规则来调整时间窗。新的时间窗上界 $(t_{\max, \text{new}}^{(n)})$ 由以下更新规则计算得出：
    $$t_{\max, \text{new}}^{(n)} = t_{\max}^{(n)} + \lambda \cdot \left( (\min(t_i^{(n)}) - t_{\min}^{(n)}) - \frac{(t_{\max}^{(n)} - t_{\min}^{(n)})}{2} \right)$$
    其中，$\lambda$ 是控制调整速率的唯一超参数。该规则根据最早脉冲时间与窗口中心的偏离程度，对当前窗口大小进行乘性缩放，从而实现双向自适应调整。

* 层间传播机制：调整后的时间窗边界被传递至下一层，即下一层的起始时间被设定为当前层更新后的结束时间：
    $$t_{\min}^{(n+1)} = t_{\max, \text{new}}^{(n)}$$

该机制的实现充分考虑了硬件资源的约束，采用了轻量级的计算策略，确保在FPGA平台上能够高效运行。通过这种自适应调整，系统不仅提高了编码效率，还增强了模型对输入信号变化的适应能力。
## 4. HARDWARE ARCHITECTURE
本章详细阐述了一款为实现高效、低功耗模式识别而设计的定制混合加速器。其核心架构思想在于协同集成一个用于空间特征提取的卷积神经网络（CNN）和一个用于后续事件驱动分类的脉冲神经网络（SNN），并通过一系列层次化的设计原则来应对两者在计算模式上的根本性差异。

### 4.1 可编程逻辑整体架构

本硬件架构在顶层设计上呈现为一个清晰的二分式结构，由一个CNN前端特征提取器和一个SNN后端分类器构成。面对CNN数据流驱动的密集计算模式与SNN事件驱动的稀疏计算模式之间的显著不匹配，设计的核心创新在于采用了“全局异步、局部同步”（GALS）的架构范式。通过为两个子系统配置独立的时钟域，我们得以对其性能与功耗进行解耦和协同优化。

两个异步域之间的桥梁是一个速率无关的握手协议，它允许作为数据消费者的SNN根据自身的处理延迟对前端CNN施加反压，从而确保了数据流的鲁棒性。整个系统的处理流程是一个高效的前馈流水线：CNN模块将输入的空间信息（图像）转换为高维特征图，再由一个关键的时间编码器将其转换为蕴含时序信息的稀疏脉冲事件流；随后，SNN模块对这些事件进行解码与分类，最终输出预测结果。这种设计将CNN强大的空间表征能力与SNN高效的事件处理机制有机地结合起来。
### 4.2 深度可分离卷积模块

CNN模块被设计成一个深度流水线化的流式处理引擎，其首要目标是以最小的片上存储资源完成高效的空间特征提取。为实现这一目标，架构采用了行缓冲（line buffer）机制来代替传统的帧缓冲（frame buffer），仅需缓存计算卷积窗口所必需的几行数据，从而极大地降低了对SRAM的需求。在计算方面，模块选用了高效率的深度可分离卷积，并通过精细的流水线设计来满足高吞吐率的要求。

该模块最关键的功能是作为连接空间域与时空域的桥梁。其末端的时间编码器负责将CNN输出的激活特征图转换为SNA能够处理的脉冲序列。在设计上，该编码器在并行计算出所有通道的脉冲时间后，通过一个串行化的握手协议逐一发送脉冲。这一设计决策是一个关键的权衡，它优先考虑了接口的简洁性、低成本和低功耗，而非追求理论上的最大并行度，这对于一个资源受限的嵌入式系统而言是一个高度务实的选择。

### 4.3 SNN 模块

SNN模块负责对前端传入的稀疏脉冲事件进行分类。考虑到纯粹的、完全异步的SNN硬件实现通常伴随着极高的控制逻辑复杂度，我们提出了一种事件驱动通信与层同步计算相结合的混合执行模型。该模型在宏观上是一个层级间的流水线，其中各层之间的通信是事件驱动的，脉冲以地址事件表示（AER）的形式异步传播，保留了SNN稀疏通信的能效优势。

然而，每一层内部的计算则被组织成一个同步的批处理过程。当来自前一层的所有脉冲事件被缓存后，一个主控制器会启动一个“计算波前”，以同步的方式在该层完成所有神经元的状态更新。这种设计极大地简化了控制逻辑，使系统状态在每个处理阶段的边界都清晰可预测，同时也天然地支持了粗粒度时钟门控，仅在层被激活时才消耗动态功耗。围绕这一核心模型，每个SNN层都配备了独立的存储（ROM用于权重，RAM用于神经元状态），并由最终的ArgMax单元根据膜电位做出分类决策。

### 4.4 参数融合与优化

为了最大限度地发挥硬件潜力，本架构还结合了编译期的参数融合优化技术。这是一种软硬件协同设计的体现，通过在推理前将多个连续的计算操作（如卷积、批归一化和ReLU激活）在数学上合并为一个等效的单一操作，显著减少了运行时的内存访问和计算开销。这种融合技术将算法有效地映射到硬件的计算流中，进一步降低了延迟和功耗，对于提升整个加速器的最终效率至关重要。
## 5. IMPLEMENTATION AND RESULTS
### 5.1 数据集、预处理和实验环境
### 5.2 模型性能分析
软件：不同模型架构的性能对比：准确率、精确率、召回率、F1分数等指标
混淆矩阵：各类情绪分类的预测结果
鲁棒性分析：加入不同强度的高斯噪声，模拟实际工作环境
### 5.3 硬件性能分析
FPGA的实际准确率
吞吐量
FPGA资源占用
量化分析：从32、16位、8位、6位到4位
## 6. CONCLUSION
### 6.1 研究总结
### 6.2 未来工作展望
