# Design of an Efficient TTFS-SNN-Based EEG Emotion Recognition System on Lightweight FPGA
基于 TTFS-SNN 的高效 EEG 情绪识别系统轻量 FPGA 实现
## 摘要
**关键词：** Spiking Neural Network (SNN)；Depthwise Separable Convolution；Energy-Efficient；Lightweight

## 1. INTRODUCTION

情绪在人类的认知、决策与社会交互过程中扮演着核心角色。随着人机交互、情感计算与心理健康监测等领域的快速发展，情绪识别（Emotion Recognition）已成为构建智能化系统的重要基础[1]。然而，当前的科学挑战不仅在于识别离散的情绪类别，更在于理解并持续追踪个体情绪状态的动态演化过程。现有研究多集中于短时、刺激驱动的情绪分类任务，而现实环境中的智能系统亟需具备长期、低侵入性、个体化的情绪监测能力，以适应个体差异与情境变化[2]。因此，这要求情绪识别方法从离散分类任务转向连续表征与个体化建模的新研究范式。

在情感计算中，面部表情、语音信号、语义文本及生理指标等多模态特征已被广泛用于情绪识别。然而，这些外显信号往往容易受到环境光照、语境差异及文化因素的影响，从而影响识别的稳定性与普适性[3]。相比之下，脑电图（EEG）能够直接反映大脑在情绪加工过程中的神经电活动，不依赖外部表现形式。凭借毫秒级时间分辨率，EEG 可以捕捉情绪状态的瞬时动态变化，为揭示情绪的神经机制及实现高精度识别提供了独特优势[4]。随着可穿戴技术与柔性电极材料的不断进步，轻量化 EEG 设备的出现使得连续、非侵入式情绪监测成为可能，为构建真正以人为中心的情绪计算系统奠定了基础。

在EEG情绪识别领域，传统机器学习（ML）方法，如支持向量机（SVM）、k近邻（kNN）及随机森林（RF）一直是研究的基础。近年来，许多工作致力于通过引入新的优化算法[5]或构建集成模型[6]来改进这些经典方法。然而，这些改进后的方法在根本上仍依赖于繁琐的信号预处理和人工特征提取，导致模型泛化性受限。为克服人工特征工程的局限并进一步提升模型性能，研究重心逐渐转向深度学习模型。以卷积神经网络（CNN）[7, 8, 9]、循环神经网络（RNN）[10]和图卷积网络（GNN）[11, 12]为代表的模型，凭借强大的时空特征自动学习能力，在多个公开数据集上取得了领先的分类精度。然而，这些模型的卓越性能与可穿戴设备的低功耗、低延迟需求之间存在内在矛盾。一方面，深度模型通常依赖大规模参数与密集乘加（MAC）运算，计算与存储代价高昂；另一方面，其同步、密集的计算范式与 EEG 信号的稀疏、动态特性存在根本不匹配[13, 14]。即便采用模型压缩、剪枝或量化等轻量化技术，仍难在边缘设备上兼顾能效与实时性[15, 16]。因此，解决该问题的关键不在于算法微调，而在于计算范式的根本转变。

受生物神经系统启发的类脑计算提供了一种全新的能效最优计算思路。脉冲神经网络作为类脑计算的核心模型，采用异步、事件驱动的计算机制，仅在触发事件时激活神经元，从而显著降低动态功耗并减少冗余计算[17, 19]。这种稀疏触发特性与 EEG 信号的稀疏、动态特性高度契合，使得 SNN 在建模情绪相关脑电动态时具有天然优势。已有研究验证了 SNN 在情绪识别与压力检测任务中的可行性。例如，Kumar 等[20]在类脑硬件上实现了 EEG 信号解码，展示了低功耗情绪识别的潜力；Doborjeh 等[21]则利用递归式 SNN 有效建模了情绪动态过程。这些成果表明，类脑计算有望成为实现连续、实时、低功耗情绪识别的关键技术路径。

在面向边缘的情感识别的设备中，实时低能耗推理是核心挑战[22]。通用 CPU/GPU 指令驱动且能耗高，难以在能效受限场景保持高效运算[23, 24]；MCU 虽低功耗但并行算力有限，难以满足深度模型的低延迟需求[15, 16]。相比之下，现场可编程门阵列（FPGA）以其可重构并行架构与对数据流的细粒度控制，成为实现 SNN 推理加速的有力平台[25, 26]。尽管 FPGA 的静态功耗通常高于MCU，但通过并行化与流水线化设计，energy-per-inference显著更优，并在延迟方面具有天然优势。同时，其设计理念与可移植性使其可作为面向未来类脑 ASIC 的过渡平台。由此，结合 FPGA 的可重构特性与 SNN 的事件驱动计算机制，可构建兼具低功耗、高并行与可扩展性的 EEG 情绪识别系统架构[18, 27]。

尽管 SNN 在事件驱动计算和稀疏激活层面具有显著优势，不过，其在处理高维、多通道 EEG 的表征能力上尚未完全成熟[27]。为了融合传统神经网络强大的特征表征能力和SNN高效的事件驱动计算模式，一种有效的策略是构建混合式架构。为此，本研究采用深度可分离卷积来构建一个轻量级的CNN特征提取前端，旨在以极低的计算成本从EEG信号中提取显著的时空特征；[28]随后，这些特征被编码为稀疏脉冲序列，交由SNN后端进行低功耗的分类决策，从而在性能与效率之间取得最佳平衡。

在设计一个有效的基于 SNN 的系统时，最后一个关键要素是编码方案，它负责将来自 CNN 的连续值特征转换为 SNN 所需的时间脉冲域。已有多种编码方法被提出，包括速率编码、人口编码、相位编码和首脉冲时间编码等。其中，速率编码通过脉冲发放频率来表示特征幅值，生物合理性较高，但需要较长时间窗口和大量脉冲，导致延迟增加和功耗上升[29]。人口编码依赖神经元群体的集体活动来表示信息，抗噪性强，但需要更多神经元参与，增加了硬件资源开销[30]。相位编码则通过脉冲与背景振荡信号的相位关系来表示信息，能捕捉时序特征，但在硬件实现中复杂度较高[31]。相比之下，TTFS（Time-to-First-Spike）编码将连续特征的幅值信息压缩为单次脉冲的发放时刻，从而在时间域上实现高度稀疏化：信息主要由脉冲发生的先后顺序与精确时间承载，而非长期的脉冲频率。这种表示显著减少了单位信息所需的脉冲总数与激活窗口长度，从而在实时性和动态能耗上带来明显优势，尤其适合对延迟和能耗敏感的边缘 SNN 部署[32,33]。

综上所述，尽管SNN、高效卷积和硬件加速都是活跃的研究领域，但本文旨在解决将这些元素协同设计成一个整体系统的需求。我们提出了一个基于FPGA的轻量级EEG情绪识别系统，该系统将深度可分离卷积前端与基于TTFS的SNN后端集成在一起。本研究的主要贡献如下：

[1] X. Li, Y. Zhang, P. Tiwari, et al., “EEG based emotion recognition: A tutorial and review,” *ACM Comput. Surv.*, vol. 55, no. 4, pp. 1–57, 2022.

[2] R. Pillalamarri and U. Shanmugam, “A review on EEG-based multimodal learning for emotion recognition,” *Artif. Intell. Rev.*, vol. 58, no. 5, p. 131, 2025.

[3] X. Li, D. Song, P. Zhang, et al., “Exploring EEG features in cross-subject emotion recognition,” *Front. Neurosci.*, vol. 12, p. 162, 2018.

[4] A. Y. Begum, E. E. Lawrence, M. Saravanan, et al., “Advanced biosignal processing and emotion recognition through artificial intelligence,” in *Applied Mathematical Modeling for Biomedical Robotics and Wearable Devices*. Academic Press, 2026, pp. 59–78.

[5] F. Tian, et al., “The three-lead EEG sensor: Introducing an EEG-assisted depression diagnosis system based on ant lion optimization,” *IEEE Trans. Biomed. Circuits Syst.*, vol. 17, no. 6, pp. 1305–1318, 2023.

[6] J. Cheng, M. Chen, C. Li, et al., “Emotion recognition from multi-channel EEG via deep forest,” *IEEE J. Biomed. Health Inform.*, vol. 25, no. 2, pp. 453–464, 2020.

[7] V. J. Lawhern, A. J. Solon, N. R. Waytowich, et al., “EEGNet: a compact convolutional neural network for EEG-based brain–computer interfaces,” *J. Neural Eng.*, vol. 15, no. 5, p. 056013, 2018.

[8] R. T. Schirrmeister, J. T. Springenberg, L. D. J. Fiederer, et al., “Deep learning with convolutional neural networks for EEG decoding and visualization,” *Hum. Brain Mapp.*, vol. 38, no. 11, pp. 5391–5420, 2017.

[9] A. Seal, S. R. et al., “DeprNet: A deep convolution neural network framework for detecting depression using EEG,” *IEEE Trans. Instrum. Meas.*, vol. 70, pp. 1–13, 2021.

[10] S. Alhagry, A. A. Fahmy and R. A. El-Khoribi, “Emotion recognition based on EEG using LSTM recurrent neural network,” *Int. J. Adv. Comput. Sci. Appl.*, vol. 8, no. 10, 2017.

[11] K. Devarajan, S. Ponnan and S. Perumal, “Enhancing emotion recognition through multi-modal data fusion and graph neural networks,” *Intelligence-Based Medicine*, p. 100291, 2025.

[12] D. Pan, H. Zheng, F. Xu, et al., “MSFR-GCN: A multi-scale feature reconstruction graph convolutional network for EEG emotion and cognition recognition,” *IEEE Trans. Neural Syst. Rehabil. Eng.*, vol. 31, pp. 3245–3254, 2023.

[13] H. Barki, N. D. Mai and W. Y. Chung, “Optimized XGBoost for multimodal affective state classification using in-ear PPG and behind-the-ear EEG signals,” *IEEE J. Biomed. Health Inform.*, 2025.

[14] X. Yi, “Energy-efficient EEG-based epileptic seizure detection: A deep learning-based spiking neural network approach,” *Procedia Comput. Sci.*, vol. 266, pp. 908–915, 2025.

[15] J. Lin, W.-M. Chen, Y. Lin, et al., “MCUNet: Tiny deep learning on IoT devices,” in *Adv. Neural Inf. Process. Syst.*, vol. 33, 2020, pp. 11711–11722.

[16] R. Sanchez-Iborra and A. F. Skarmeta, “TinyML-enabled frugal smart objects: Challenges and opportunities,” *IEEE Circuits Syst. Mag.*, vol. 20, no. 3, pp. 4–18, 2020.

[17] W. Maass, “Networks of spiking neurons: the third generation of neural network models,” *Neural Netw.*, vol. 10, no. 9, pp. 1659–1671, 1997.

[18] X. Zhang, J. Zhang, H. Huang, et al., “An Asynchronous RISC-V-based SNN Processor with Custom ISA Extensions for Programmable On-Chip Learning,” in *Proc. 29th IEEE Int. Symp. Asynchronous Circuits Syst. (ASYNC)*, IEEE, 2025, pp. 1–8.

[19] J. Bartels, O. Gallou, H. Ito, et al., “An event-driven neural network for monitoring of epileptic seizures on low-power neuromorphic hardware,” *bioRxiv*, 2024.

[20] N. Kumar, G. Tang, R. Yoo, et al., “Decoding EEG with spiking neural networks on neuromorphic hardware,” *Trans. Mach. Learn. Res.*, 2022.

[21] W. Alzhrani, M. Doborjeh, Z. Doborjeh, et al., “Emotion recognition and understanding using EEG data in a brain-inspired spiking neural network architecture,” in *Proc. 2021 Int. Joint Conf. Neural Netw. (IJCNN)*, IEEE, 2021, pp. 1–9.

[22] Z. Aalam, S. Aziz, K. L. Lew, et al., “Real-Time Emotion Detection Using Artificial Intelligence: A Review,” *Int. J. Robot. Autom. Sci.*, vol. 7, no. 1, pp. 104–110, 2025.

[23] S. Mittal, “A survey of techniques for approximate computing,” *ACM Comput. Surv. (CSUR)*, vol. 48, no. 4, pp. 1–33, 2016.

[24] A. Reuther, P. Michaleas, M. Jones, et al., “Survey of machine learning accelerators,” in *Proc. 2020 IEEE High Performance Extreme Computing Conf. (HPEC)*, 2020, pp. 1–12.

[25] V. Sze, Y.-H. Chen, T.-J. Yang, et al., “Efficient processing of deep neural networks: A tutorial and survey,” *Proc. IEEE*, vol. 105, no. 12, pp. 2295–2329, 2017.

[26] K. Guo, S. Zeng, J. Yu, et al., “A survey of FPGA-based neural network inference accelerators,” *ACM Trans. Reconfig. Technol. Syst. (TRETS)*, vol. 12, no. 1, pp. 1–26, 2019.

[27] S. Liu, H. Chu, Y. Feng, et al., “PicoSleepNet: An ultra lightweight sleep stage classification by spike neural network using single-channel EEG signal,” *IEEE J. Biomed. Health Inform.*, 2025.

[28] A. G. Howard, M. Zhu, B. Chen, et al., “MobileNets: Efficient convolutional neural networks for mobile vision applications,” *arXiv preprint arXiv:1704.04861*, 2017.

[29] A. A. M. Andrew, “Spiking neuron models: Single neurons, populations, plasticity,” *Kybernetes*, vol. 32, no. 7/8, 2003.

[30] C. Eliasmith and C. H. Anderson, *Neural engineering: Computation, representation, and dynamics in neurobiological systems*. MIT Press, 2003.

[31] C. Kayser, M. A. Montemurro, N. K. Logothetis, et al., “Spike-phase coding boosts and stabilizes information carried by spatial and temporal spike patterns,” *Neuron*, vol. 61, no. 4, pp. 597–608, 2009.

[32] H. Mostafa, “Supervised learning based on temporal coding in spiking neural networks,” *IEEE Trans. Neural Netw. Learn. Syst.*, vol. 29, no. 7, pp. 3227–3235, 2017.

[33] M. Zhang, S. Wang, J. Wu, et al., “Toward energy-efficient spike-based deep reinforcement learning with temporal coding,” *IEEE Comput. Intell. Mag.*, vol. 20, no. 2, pp. 45–57, 2025.



## 2. METHODOLOGY AND ALGORITHM

当前，可穿戴 EEG 情绪识别设备的主要挑战在于传统深度神经网络的计算范式与 EEG 信号的生理特性存在根本不匹配。前者依赖密集且同步的矩阵运算，而后者本质上表现为稀疏、事件驱动的神经活动。这种差异导致现有模型难以在功耗和算力受限的设备上高效运行。为实现低功耗、低延迟的边缘情绪识别系统，需要一种既能充分捕获生物信号时空特征，又能在资源受限硬件上高效执行的新型计算架构。



### A.Neuron Model and TTFS Coding

脑电（EEG）信号作为一种典型的非平稳时序信号，蕴含了大量与情绪状态相关的动态信息，其时域波动与事件触发过程具有显著的时间依赖性。脉冲神经网络（Spiking Neural Network, SNN）通过膜电位积累、阈值触发与事件驱动的计算机制，能够以更生物启发的方式表达神经活动的时序特征，因而在EEG等时间敏感型任务中表现出潜在优势。

在SNN的设计中，神经元模型是定义时域动态与信息编码方式的关键。当前常用的脉冲神经元模型主要包括 Leaky Integrate-and-Fire (LIF) []、Izhikevich []、Hodgkin–Huxley (HH) [] 以及 Spike Response Model (SRM)[]。其中，HH模型能够精确刻画神经元膜电位的生理演化，被视为生物神经计算的黄金标准，但计算复杂度极高，难以部署在低功耗平台上。Izhikevich与SRM模型在生物真实性与计算效率之间取得平衡，但依然需要较高的资源开销。LIF 模型因其结构简洁、数学形式可离散化而成为工程实现中最常用的神经元模型。其膜电位随时间的演化可表示为

$V[t+1] = \alpha V[t] + I[t],$

其中，$\alpha = e^{-\Delta t / \tau} $为指数衰减因子，$I[t]$表示输入电流。这一形式在算法层面易于仿真，但在硬件实现中仍面临一定挑战：衰减项 $\alpha V[t]$ 需要在每个时间步执行一次乘法操作，而当网络规模较大时，大量乘法运算将占用可观的 DSP 资源或查找表，从而增加功耗并降低并行效率。尤其在 FPGA 或低功耗 SoC 等资源受限平台上，LIF 模型的指数衰减机制成为制约其实时部署与扩展能力的主要瓶颈。

为解决LIF等模型在计算和硬件实现上的局限性，并充分发挥SNN的稀疏计算优势，本研究在编码范式与神经元模型两个层面进行了协同设计。

<img src="%E8%AE%BA%E6%96%87.assets/image-20251028222808313.png" alt="image-20251028222808313" style="zoom:67%;" />

本研究采用的核心编码范式是首脉冲时间编码（Time-To-First-Spike, TTFS）。TTFS编码方式通过将更强的输入激转化为更早的脉冲发放时间，并且每个神经元在一个计算周期内最多只发放一个脉冲，实现了极致的脉冲稀疏性，确保了最低的理论功耗和最快的响应速度。此外，本文采用了B1脉冲神经元模型[]以契合该编码方式。B1模型的核心就是引入了一个级联时间窗（Cascading Time Window）机制，为TTFS编码提供了完美的硬件友好型实现框架。该模型的核心是将复杂的神经元动力学简化为一个分段线性的过程，省去了在硬件上实现成本高昂的指数运算与乘法衰减项。其动态特性由时间窗（Temporal Bounds）$[t_{\min}^{(n)}, t_{\max}^{(n)}]$ 划分为两个计算阶段。

网络的第 $n$ 层的时间窗 为$[t_{\min}^{(n)}, t_{\max}^{(n)}]$。每一层的$t_{\min}^{(n)}$被定义为上一层的$t_{\max}^{(n-1)}$，即 $t_{min}^{(n)} =^{def} t_{max}^{(n-1)}$。
其膜电位演化可描述为：
$$
\epsilon \frac{dV_i^{(n)}(t)}{dt} =
\begin{cases}
\sum_j W_{ij}^{(n)} H(t - t_j^{(n-1)}), & t < t_{\min}^{(n)} \quad  \\
1, & t_{\min}^{(n)} \le t \le t_{\max}^{(n)} \quad 
\end{cases}
$$
其中，$\epsilon$ 为时间常数，$H(\cdot)$ 为亥维赛阶跃函数，$W_{ij}^{(n)}$ 为突触权重。

在 $t < t_{\min}^{(n)}$ 的时间区间内，神经元膜电位 $\frac{dV_i^{(n)}}{dt}$ 的斜率由加权输入脉冲 $\sum_j W_{ij}^{(n)} H(t - t_j^{(n-1)})$ 决定。随后，在 $t_{\min}^{(n)} \le t \le t_{\max}^{(n)}$ 的时间区间内，膜电位斜率 $\frac{dV_i^{(n)}}{dt}$ 被固定为1，以恒定的速率开始线性增长。

对于第 $n$ 层的神经元 $i$，其输出脉冲的时刻 $t_i^{(n)}$ 是基于上一层的输入 $t_j^{(n-1)}$ 和阈值 $\vartheta_i^{(n)}$计算得出的。由B1模型的膜电位动力学，可直接推导出该前向传播方程如式（1）所示：

$$
t_i^{(n)} = t_{\min}^{(n)} + \tau_c \vartheta_i^{(n)} - \sum_j W_{ij}^{(n)} \bigl( t_{\min}^{(n)} - t_j^{(n-1)} \bigr) \quad
$$

若神经元i的脉冲发放时间 $t_i^{(n)}$ 超过本层的时间窗$t_{\max}^{(n)}$，该神经元便被视为未发放脉冲，在本计算周期内将保持沉默，不产生任何输出脉冲。

### B. Layer Structure

在资源受限的轻量级FPGA平台上设计神经网络时，模型的计算复杂度、功耗预算与推理延迟是与识别精度同等重要的核心考量[25, 26]。为实现算法性能与硬件效率的最佳平衡，本研究提出一种面向硬件优化的轻量级混合神经网络，将高效的时空特征提取与事件驱动的脉冲计算相结合，以弥合算法结构与信号特性之间的差距。==如图所示==，网络前端采用深度可分离卷积结构，用于高效提取 EEG 信号的时空特征并显著降低参数量和乘加复杂度。中间部分引入一种硬件友好的无除法 TTFS（time-to-first-spike）时间编码模块，将连续波形映射为稀疏脉冲序列，从而适配事件驱动计算机制。后端由基于TTFS编码的脉冲神经网络完成分类决策，在保持竞争性分类精度的同时，实现低功耗和低延迟推理。该架构在设计中充分考虑 FPGA 与可穿戴设备的实现约束，为实时、能效优化的 EEG 情绪识别提供了一种可行的技术途径。以下是上述三个模块的详细说明。

1）Efficient Spatio-temporal Feature Extraction Module

在处理多通道EEG信号时，首要挑战是如何在有限的硬件资源下高效捕获信号内部复杂的空间与时间依赖关系。传统的卷积神经网络（CNN）虽然表征能力强[7, 8]，但其标准的卷积操作涉及大量的乘加（MAC）运算和参数存储，这在资源受限的FPGA上会迅速消耗宝贵的DSP单元和BRAM资源，成为性能瓶颈。相关工作在轻量化网络架构方面已取得显著进展。如SqueezeNet 和 MobileNets [] 等研究已经证明，通过 $1 \times 1$ 卷积核压缩通道或将标准卷积分解为深度卷积和逐点卷积，可以在保持性能的同时极大降低模型复杂度。本模块即由深度可分离卷积（Depthwise Separable Convolution）作为网络的基础构建单元。其中深度卷积为输入的$C_{in}$个特征通道分别应用独立的卷积核，执行逐通道的空间滤波操作；之后，通过 $1 \times 1$ 卷积核对深度卷积的$C_{in}$个通道的输出进行线性组合，并将其映射到 $C_{out}$ 个输出通道。

| **运算类型**   | **参数量 (Parameters)**                                      | **计算成本 (MACs)**                                          |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 传统卷积       | $K^2 \cdot C_{in} \cdot C_{out}$                             | $K^2 \cdot C_{in} \cdot C_{out} \cdot H_{out} \cdot W_{out}$ |
| 深度可分离卷积 | $K^2 \cdot C_{in} + C_{in} \cdot C_{out}$                    | $(K^2 \cdot C_{in} + C_{in} \cdot C_{out}) \cdot H_{out} \cdot W_{out}$ |
| 成本降低比率   | $\frac{K^2 C_{in} + C_{in} C_{out}}{K^2 C_{in} C_{out}} = \frac{1}{C_{out}} + \frac{1}{K^2}$ |                                                              |

更重要的是，深度可分离卷积将复杂的运算分解为两个规整、独立的标准模块的特性为FPGA部署时提供了可拓展和可复用的硬件实现结构，使其极易于构建深度流水线（Pipeline）架构，实现硬件资源的高度复用与高吞吐量的实时数据处理。

整个时空特征提取模块的过程描述如下。

$$\left\{ \begin{aligned} H_{Block}^{(i)}(X) &= f_{ReLU}^{(i)}\left(f_{BN}^{(i)}\left(f_{PW}^{(i)}\left(f_{DW}^{(i)}(X)\right)\right)\right) \\ F_{out} &= H_{Block}^{(2)}\left(H_{Block}^{(1)}(F_{in})\right) \end{aligned} \right.$$

其中$F_{in}$是整个前端模块的输入特征图，$X$ 代表块函数的输入，$H_{Block}^{(i)}$ 是第 $i$ 个深度可分离卷积块，$f_{DW}^{(i)}$ 是第 $i$ 个块的Depthwise Convolution运算，$f_{PW}^{(i)}$ 是第 $i$ 个块的逐点卷积运算，$f_{BN}^{(i)}$ 是第 $i$ 个块的Batch Normalization运算，$f_{ReLU}^{(i)}$ 是第 $i$ 个块的ReLU激活函数，$F_{out}$ 是整个前端模块（的最终输出特征。

2）TTFS Temporal Encoding Module

将前端ANN模块提取的连续激活值转换为后端SNN所需的稀疏、离散的脉冲序列，是连接这两种计算范式的关键步骤。SNN的低功耗潜力源于其事件驱动的计算范式，即只有在接收到脉冲时才进行计算。因此，一个高效的编码机制应当以最少的脉冲数量来承载最丰富的信息。相关工作虽然探索了多种编码方案，但如速率编码（Rate Coding）[]、人口编码（Population Coding）[]与相位编码（Phase Coding）[]等，均因高延迟、高资源消耗或高实现复杂度，无法同时满足本系统对轻量化和实时性的严苛约束。

本模块采用了首脉冲时间编码（Time-To-First-Spike, TTFS），该机制将信息强度完整压缩在单个脉冲的精确发放时刻上，实现了极致的脉冲稀疏性与最低的理论延迟[]。然而，如下式所示，标准的TTFS编码机制依赖于浮点除法运算，这在硬件上实现代价高昂。

$$x_{norm} = \frac{x - x_{min}}{x_{max} - x_{min}}$$

为解决此问题，本模块采用了一种专为硬件优化的无除法TTFS编码器。其核心是将高成本的算术除法替换为不消耗逻辑单元的逻辑位移操作。==如式 所示==该机制首先在训练中跟踪激活值的动态范围scale；然后，它不直接使用该范围 scale作为除数，而是计算出一个大于scale的最小的2的整数次幂作为新的归一化分母$S_p$。

$x_{norm} = \frac{x - x_{min}}{2^N}$

整个TTFS编码模块的转换过程可描述如下：

$$\left\{ \begin{aligned} S_p &= 2^{\lceil \log_2(V_{max} - V_{min}) \rceil} \\ V_{norm} &= f_{clip}\left(\frac{F_{out} - V_{min}}{S_p}, 0, 1\right) \\ T_{spike} &= T_{max} - V_{norm} \cdot (T_{max} - T_{min}) \end{aligned} \right. $$

其中 $F_{out}$ 是来自前端卷积模块的输入特征， $V_{min}$ 和 $V_{max}$ 是训练时跟踪的激活值动态范围， $S_p$ 是计算出的二次幂缩放因子，$f_{clip}$ 是钳位函数， $T_{spike}$ 是最终输出的脉冲时间。

3）Adaptive Temporal Spiking Neural Module

本模块是系统的事件驱动决策后端，负责处理由TTFS编码器 生成的稀疏时序脉冲（$T_{spike}$），并实现最终的情绪类别判别。该模块基于多层全连接的脉冲神经元构建，其设计充分发挥了SNN的低功耗潜力，并通过时序编码捕捉EEG信号的动态特征。

该网络架构的核心特点在于信息处理在时间维度上的级联划分（Cascading Time Window）。网络的每一层（$n$）都在一个专属的、连续的时间窗 $[T_{min}^{(n)}, T_{max}^{(n)}]$ 内进行运算。层与层之间的时间窗首尾相连，即 $T_{min}^{(n)} =^{def} T_{max}^{(n-1)}$，确保了信号能够有序地、逐层地在时间维度上传播。

为适配TTFS编码，该模块的前向传播逻辑区分了隐藏层与输出层。隐藏层的功能是对输入的脉冲时间向量 $T_j^{(n-1)}$ 进行非线性时域变换。根据式（1），对于第 $n$ 层的神经元 $i$，其输出脉冲时刻 $T_i^{(n)}$ 由下式得出。

$$T_i^{(n)} = f_{clip}\left( \sum_j W_{ij}^{(n)} (T_j^{(n-1)} - T_{min}^{(n)}) + \vartheta_i^{(n)} + T_{min}^{(n)}, \ T_{min}^{(n)}, T_{max}^{(n)} \right)$$

其中 $W_{ij}^{(n)}$ 是权重，$\vartheta_i^{(n)}$ 是可训练的阈值， $f_{clip}$ 函数确保脉冲时间在$[T_{min}^{(n)}, T_{max}^{(n)}]$内。

输出层被设计为非脉冲的积分单元，其职责是将在其时间窗口内接收到的所有脉冲影响进行积分。在窗口结束时，神经元 $i$ 内部累积的总电位值（Logit）$L_i$ 可得出：

$$L_i = \sum_j W_{ij}^{(L)} (T_{min}^{(L)} - T_j^{(L-1)}) + (T_{max}^{(L)} - T_{min}^{(L)} - \vartheta_i^{(L)})$$

此过程通过时域稀疏解码，将时间域信息转换回幅度域的决策值，用于最终的分类。

然而，在TTFS编码范式中，时间窗 $[T_{min}, T_{max}]$ 是一个核心超参数，它直接影响信息表示的分辨率和训练的稳定性。在深度网络训练过程中，各层激活值的统计分布是动态变化的，采用一个静态、预设的时间窗会严重制约模型的学习与表达能力。要理解其局限性，我们必须首先分析该模块的梯度传播特性。

根据隐藏层的正向传播计算，并应用链式法则，我们可以推导出总损失 $L$ 对特定权重 $W_{ij}^{(n)}$ 的梯度 $\frac{\partial L}{\partial W_{ij}^{(n)}}$为

$$\frac{\partial L}{\partial W_{ij}^{(n)}} = \frac{\partial L}{\partial T_i^{(n)}} \cdot \frac{\partial T_i^{(n)}}{\partial W_{ij}^{(n)}} = \frac{\partial L}{\partial T_i^{(n)}} \cdot (T_j^{(n-1)} - T_{min}^{(n)})$$

这个梯度公式清晰地揭示了，权重的更新幅度与梯度项 $(T_j^{(n-1)} - T_{min}^{(n)})$ 强相关。这直接导致了时间窗设置不当会有梯度不稳定的风险。因此，一个静态的时间窗无法适应网络训练中动态变化的激活值分布。为此，我们引入了基于活动依赖的在线时间窗调整机制。该机制在每个训练批次中实时监控各隐藏层的脉冲发放动态，并据此对后续层级的时间窗进行动态重校准。

该机制的具体实现是一种乘性增益控制：在每个训练迭代中，系统会首先实时记录当前层 $n$ 在所有样本中产生的最早脉冲时间 $T_{earliest}^{(n)}$。基于该时间，机制采用乘性增益规则来调整时间窗，其新的时间窗上界 $T_{max, new}^{(n)}$ 由以下更新规则计算得出：

$$T_{max, new}^{(n)} = T_{max}^{(n)} + \lambda \cdot \left( (T_{earliest}^{(n)} - T_{min}^{(n)}) - \frac{T_{max}^{(n)} - T_{min}^{(n)}}{2} \right)$$

其中，$\lambda$ 是控制调整速率的唯一超参数。该规则根据最早脉冲时间与窗口中心的偏离程度，对当前窗口大小进行乘性缩放，以实现双向自适应调整。调整后的时间窗边界 $T_{max, new}^{(n)}$ 随即被传递至下一层，作为其新的起始时间 $T_{min}^{(n+1)}$。



## 4. IMPLEMENTATION AND RESULTS

A. Experimental Details

1）Datasets

为保证与既往研究的可比性，本研究仅采用公开的**EEG**数据集作为评估基准：SEED 系列（SEED、SEED-IV、SEED-V）、DEAP 与 DREAMER。SEED 由上海交通大学 BCMI 团队采集，包含 15 名受试者的 62 通道 EEG，三次会话记录，刺激为若干电影片段（单段约 4 分钟），常见预处理包括下采样至 200 Hz、带通滤波及频域特征（如差分熵）提取（Zheng et al., 2016）。SEED-IV 为 SEED 在情感类别上的四类扩展，保留 62 通道与多会话设计，常用于四分类任务验证；SEED-V 则在被试规模与情感细粒度上进一步扩展并提供预计算的频域特征，便于更细致的情感分类比较。DEAP 包括从 32 名受试者（17 名男性、15名女性）收集的 32 通道脑电图数据。受试者的情绪是通过一分钟长的音乐视频剪辑来诱导的。每次刺激后，受试者都会根据 Russell （1980） 提出的二维情绪量表对他们的情绪体验进行评分。DREAMER 采用便携设备采集约 23 名被试的 14 通道 EEG（采样 128 Hz），因其轻量 EEG 配置常被用于轻量化模型的性能验证。为保证比较公平性，本研究在所有数据集上仅使用 EEG 通道，统一采用各自通用的预处理约定，随后将处理结果用于后续特征提取与分类评估。

2） Data preprocessing

本研究的数据预处理流程旨在从原始的多通道脑电（EEG）信号中提取具有判别性的时空特征，并对其进行平滑处理以增强信号的稳定性。整个流程主要包括基线校正、数据分段、特征提取、空间映射和时间动态平滑，具体步骤如下。

首先，我们对原始的多通道脑电信号进行基线校正。采用Z-Score标准化方法，利用每个试次（trial）开始前一段时间的静息态数据作为基线。具体而言，我们计算基线时段内每个通道信号的平均值和标准差，并利用这两个统计量对整个试次的信号进行标准化处理。该步骤有效地移除了通道间的基线漂移，并减少了不同试次间的信号差异。

完成基线校正后，我们将连续的脑电信号分割成固定长度的样本。我们使用一个固定长度的非重叠滑动窗口对每个试次的数据进行分割。为了更好地捕捉信号的动态变化，每个样本被进一步分解为多个连续的、更短的时间帧，形成一个维度为 T × C × S 的张量，其中T代表时间帧的数量，C为通道数，S为每个时间帧的采样点数。

接下来是特征提取阶段。针对每个时间帧，我们计算其功率谱熵（Power Spectrum Entropy, PSE）作为核心特征。功率谱熵能够有效衡量信号在频域中的不确定性或复杂性。通过该计算，T × C × S 的原始信号样本被转换为一个 T × C 的特征矩阵。

为了保留并利用电极在头皮上的空间拓扑信息，我们将提取的多通道特征映射到一个二维网格中。该映射关系根据标准电极系统的物理位置来确定，使得空间上相邻的电极在特征图上也保持邻近。经过此步骤，每个样本被表示为多个连续的二维特征图，构成了一个具有时空结构的特征序列。

最后，为了对特征序列进行平滑处理并建模其内在的时间动态性，我们引入了线性动力学系统（Linear Dynamical System, LDS）对每个试次内的特征序列进行时间上的平滑。

|          | Sample Shape |         |                |
| -------- | ------------ | ------- | -------------- |
| Datasets | SIZE         | CHANNLE | Sliding window |
| SEED     | 8*9          | 4       | 1s             |
| SEED IV  | 8*9          | 4       | 1s             |
| SEED V   | 8*9          | 4       | 1s             |
| DEAP     | 6*7          | 6       | 1.5s           |
| DREAMER  | 4*5          | 9       | 1.5s           |

 

### B. Experimental Settings:

整个实验环境基于如下计算机配置：12 核 vCPU Intel(R) Xeon(R) Platinum 8255C 处理器（主频 2.50 GHz）与 NVIDIA GeForce RTX 2080 Ti（11 GB 显存）GPU，运行在 Ubuntu 22.04 系统下的 Python 3.12 环境中，使用 PyTorch 2.3.0 与 CUDA 12.1。
对于机器学习模型，我们参考了以往研究的经验并尝试寻找最优参数；对于深度学习模型，采用 Adamw优化器 来最小化交叉熵损失函数，学习率设为1e-4，batch size为 8，epoch设为 300，并使用早停防止过拟合。

随后，我们采用多种指标对所提出的 LSNNet 模型进行客观评估，包括 准确率（Acc）、特异性（Spe）、敏感性（Sen）、精确率（Pre） 以及 F1-score（F1） 。实验结果以平均值（mean） 和 标准差（Std） 的形式给出。

$\begin{matrix}Acc\mathrm{=}\frac{TP\mathrm{+}TN}{TP\mathrm{+}TN\mathrm{+}FP\mathrm{+}FN}\end{matrix}$

$\begin{matrix}Spe\mathrm{=}\frac{TN}{TN\mathrm{+}FP}\end{matrix}$

$\begin{matrix}Sen\mathrm{=}\frac{TP}{TP\mathrm{+}FN}\end{matrix}$

$\begin{matrix}Pre\mathrm{=}\frac{TP}{TP\mathrm{+}FP}\end{matrix}$

$\begin{matrix}F\mathrm{1=}\frac{\mathrm{2×}Pre\mathrm{×}Sen}{Pre\mathrm{+}Sen}\end{matrix}$

其中，$(TP)\mathrm{、}(TN)\mathrm{、}(FP)\mathrm{、}(FN)$分别表示真正例（True Positive）、真反例（True Negative）、假正例（False Positive）和假反例（False Negative)。

此外，为了评估模型的计算效率，我们采用 浮点运算量（FLOPs） 和 乘加运算量（Mult-Adds） 来衡量模型的整体计算复杂度。最后，将训练好的模型进行INT8量化后部署在 Xilinx Zynq-7000 SoC (XC7Z020-2CLG400) 平台上，以评估其硬件资源占用情况，其中 LUT、LUTRAM、FF 与BRAM 被用于测量模型在硬件上的最小存储资源需求。

### C. Classification Results

 

### D. ASIC Implementation

### 5.2 模型性能分析

软件：不同模型架构的性能对比：准确率、精确率、召回率、F1分数等指标
混淆矩阵：各类情绪分类的预测结果
鲁棒性分析：加入不同强度的高斯噪声，模拟实际工作环境

**后端消融对比**

- **目的：** 证明SNN后端 相较于传统ANN后端在能效上的巨大优势。
- **设计：** 保持前端（`DepthwiseSeparableConv`）完全一致。构建一个基线模型，将其后端的 `SpikingDense` 层 替换为等效拓扑的 `nn.Linear` 层。在相同条件下训练后，对比二者的**验证精度**（应相近）与**计算成本**（SNN的平均脉冲数 vs. ANN的MACs）。

**前端消融对比**

- **目的：** 证明深度可分离卷积（DSC）前端 相较于传统卷积在计算成本上的优越性。
- **设计：** 保持后端（`SpikingDense`）完全一致。构建一个对照组模型，将其前端的 `DepthwiseSeparableConv` 替换为 `nn.Conv2d`（标准卷积）。对比二者的**验证精度**（应相近）以及前端的**参数量**和**MACs**。

### 5.3 硬件性能分析
FPGA的实际准确率
吞吐量
FPGA资源占用
量化分析：从32、16位、8位、6位到4位

## 6. CONCLUSION
### 6.1 研究总结
### 6.2 未来工作展望
